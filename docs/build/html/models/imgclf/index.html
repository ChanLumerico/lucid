<!DOCTYPE html>
<html lang="en" data-accent-color="indigo" data-content_root="../../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Image Classification - Lucid 2.13.1 documentation</title><link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="LeNet" href="lenet/LeNet.html" /><link rel="prev" title="PreTrainedModelMixin" href="../mixins/PreTrainedModelMixin.html" />
      <link rel="canonical" href="https://chanlumerico.github.io/lucid/models/imgclf/" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../../_static/shibuya.css?v=44020203" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link media="print" rel="stylesheet" type="text/css" href="../../_static/print.css?v=20ff2c19" />
    <link rel="stylesheet" type="text/css" href="../../_static/badges.css?v=b1c3d602" />
    <link rel="stylesheet" type="text/css" href="../../_static/mermaid.css?v=71a6aa26" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/>
  <meta property="og:url" content="https://chanlumerico.github.io/lucid/models/imgclf/"/>
  <meta property="og:title" content="Image Classification"/>
    <meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../../index.html">
      
      
      <strong>Lucid</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">Tensor</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tensor/Tensor_.html">lucid.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor/tensor.html">lucid.tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor/operations/index.html">Tensor Operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/exp.html">lucid.exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/log.html">lucid.log</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/log2.html">lucid.log2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/sqrt.html">lucid.sqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/sin.html">lucid.sin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/cos.html">lucid.cos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/tan.html">lucid.tan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/arcsin.html">lucid.arcsin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/arccos.html">lucid.arccos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/arctan.html">lucid.arctan</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/sinh.html">lucid.sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/cosh.html">lucid.cosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/tanh.html">lucid.tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/clip.html">lucid.clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/abs.html">lucid.abs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/sign.html">lucid.sign</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/reciprocal.html">lucid.reciprocal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/square.html">lucid.square</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/cube.html">lucid.cube</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/transpose.html">lucid.transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/sum.html">lucid.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/trace.html">lucid.trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/mean.html">lucid.mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/var.html">lucid.var</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/min.html">lucid.min</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/max.html">lucid.max</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/swapaxes.html">lucid.swapaxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/round.html">lucid.round</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/floor.html">lucid.floor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/ceil.html">lucid.ceil</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/cumprod.html">lucid.cumprod</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/ufunc/cumsum.html">lucid.cumsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/add.html">lucid.add</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/sub.html">lucid.sub</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/multiply.html">lucid.multiply</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/div.html">lucid.div</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/minimum.html">lucid.minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/maximum.html">lucid.maximum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/power.html">lucid.power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/dot.html">lucid.dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/inner.html">lucid.inner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/outer.html">lucid.outer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/matmul.html">lucid.matmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/bfunc/tensordot.html">lucid.tensordot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/zeros.html">lucid.zeros</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/zeros_like.html">lucid.zeros_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/ones.html">lucid.ones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/ones_like.html">lucid.ones_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/eye.html">lucid.eye</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/diag.html">lucid.diag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/arange.html">lucid.arange</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/empty.html">lucid.empty</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/empty_like.html">lucid.empty_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/linspace.html">lucid.linspace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/full.html">lucid.full</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/operations/gfunc/full_like.html">lucid.full_like</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor/utilities/index.html">Tensor Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/reshape.html">lucid.reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/squeeze.html">lucid.squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/unsqueeze.html">lucid.unsqueeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/ravel.html">lucid.ravel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/stack.html">lucid.stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/hstack.html">lucid.hstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/vstack.html">lucid.vstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/concatenate.html">lucid.concatenate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/pad.html">lucid.pad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/repeat.html">lucid.repeat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/tile.html">lucid.tile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/flatten.html">lucid.flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/meshgrid.html">lucid.meshgrid</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/split.html">lucid.split</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/tril.html">lucid.tril</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/triu.html">lucid.triu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/broadcast_to.html">lucid.broadcast_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/expand.html">lucid.expand</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/chunk.html">lucid.chunk</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/masked_fill.html">lucid.masked_fill</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/roll.html">lucid.roll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/gather.html">lucid.gather</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/unbind.html">lucid.unbind</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/sort.html">lucid.sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/argsort.html">lucid.argsort</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/argmin.html">lucid.argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/argmax.html">lucid.argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/nonzero.html">lucid.nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/unique.html">lucid.unique</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/topk.html">lucid.topk</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/histogram.html">lucid.histogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/histogram2d.html">lucid.histogram2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/histogramdd.html">lucid.histogramdd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/where.html">lucid.where</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor/utilities/diagonal.html">lucid.diagonal</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Autograd</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../autograd/autograd.html">lucid.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd/index.html">Autograd APIs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../autograd/backward.html">lucid.autograd.backward</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../autograd/grad.html">lucid.autograd.grad</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Linear Algebra</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../linalg/linalg.html">lucid.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg/operations/index.html">Linalg Operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/det.html">lucid.linalg.det</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/inv.html">lucid.linalg.inv</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/solve.html">lucid.linalg.solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/norm.html">lucid.linalg.norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/cholesky.html">lucid.linalg.cholesky</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/eig.html">lucid.linalg.eig</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/qr.html">lucid.linalg.qr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/svd.html">lucid.linalg.svd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/matrix_power.html">lucid.linalg.matrix_power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linalg/operations/pinv.html">lucid.linalg.pinv</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Random</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../random/random.html">lucid.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random/functions/index.html">RNG Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../random/functions/seed.html">lucid.random.seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../random/functions/rand.html">lucid.random.rand</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../random/functions/randint.html">lucid.random.randint</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../random/functions/randn.html">lucid.random.randn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../random/functions/uniform.html">lucid.random.uniform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../random/functions/bernoulli.html">lucid.random.bernoulli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../random/functions/permutation.html">lucid.random.permutation</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Einstein Operations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../einops/einops.html">lucid.einops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../einops/functions/index.html">Einops Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../einops/functions/rearrange.html">lucid.einops.rearrange</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../einops/functions/reduce.html">lucid.einops.reduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../einops/functions/repeat.html">lucid.einops.repeat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../einops/functions/einsum.html">lucid.einops.einsum</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Neural Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../nn/nn.html">lucid.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/Parameter.html">nn.Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/Buffer.html">nn.Buffer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/Module.html">nn.Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/ModuleHooks.html">Module Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/functions/index.html">Neural Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/linear/index.html">Linear Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/linear/linear.html">nn.functional.linear</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/linear/bilinear.html">nn.functional.bilinear</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/activation/index.html">Activation Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/relu.html">nn.functional.relu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/leaky_relu.html">nn.functional.leaky_relu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/elu.html">nn.functional.elu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/selu.html">nn.functional.selu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/gelu.html">nn.functional.gelu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/sigmoid.html">nn.functional.sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/tanh.html">nn.functional.tanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/activation/softmax.html">nn.functional.softmax</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/attention/index.html">Attention Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/attention/scaled_dot_product_attention.html">nn.functional.scaled_dot_product_attention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/conv/index.html">Convolution Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/conv/unfold.html">nn.functional.unfold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/conv/conv1d.html">nn.functional.conv1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/conv/conv2d.html">nn.functional.conv2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/conv/conv3d.html">nn.functional.conv3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/conv/conv_transpose1d.html">nn.functional.conv_transpose1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/conv/conv_transpose2d.html">nn.functional.conv_transpose2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/conv/conv_transpose3d.html">nn.functional.conv_transpose3d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/pool/index.html">Pooling Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/avg_pool1d.html">nn.functional.avg_pool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/avg_pool2d.html">nn.functional.avg_pool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/avg_pool3d.html">nn.functional.avg_pool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/max_pool1d.html">nn.functional.max_pool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/max_pool2d.html">nn.functional.max_pool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/max_pool3d.html">nn.functional.max_pool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/adaptive_avg_pool1d.html">nn.functional.adaptive_avg_pool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/adaptive_avg_pool2d.html">nn.functional.adaptive_avg_pool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/adaptive_avg_pool3d.html">nn.functional.adaptive_avg_pool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/adaptive_max_pool1d.html">nn.functional.adaptive_max_pool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/adaptive_max_pool2d.html">nn.functional.adaptive_max_pool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/pool/adaptive_max_pool3d.html">nn.functional.adaptive_max_pool3d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/drop/index.html">Dropout Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/drop/dropout.html">nn.functional.dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/drop/dropout1d.html">nn.functional.dropout1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/drop/dropout2d.html">nn.functional.dropout2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/drop/dropout3d.html">nn.functional.dropout3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/drop/alpha_dropout.html">nn.functional.alpha_dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/drop/drop_block.html">nn.functional.drop_block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/drop/drop_path.html">nn.functional.drop_path</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/norm/index.html">Normalization Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/norm/normalize.html">nn.functional.normalize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/norm/batch_norm.html">nn.functional.batch_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/norm/layer_norm.html">nn.functional.layer_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/norm/instance_norm.html">nn.functional.instance_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/norm/group_norm.html">nn.functional.group_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/norm/global_response_norm.html">nn.functional.global_response_norm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/loss/index.html">Loss Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/loss/mse_loss.html">nn.functional.mse_loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/loss/binary_cross_entropy.html">nn.functional.binary_cross_entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/loss/binary_cross_entropy_with_logits.html">nn.functional.binary_cross_entropy_with_logits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/loss/cross_entropy.html">nn.functional.cross_entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/loss/nll_loss.html">nn.functional.nll_loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/loss/huber_loss.html">nn.functional.huber_loss</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/spatial/index.html">Spatial Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/spatial/affine_grid.html">nn.functional.affine_grid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/spatial/grid_sample.html">nn.functional.grid_sample</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/functions/util/index.html">Utility Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/util/interpolate.html">nn.functional.interpolate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/util/rotate.html">nn.functional.rotate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/util/embedding.html">nn.functional.embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/functions/util/one_hot.html">nn.functional.one_hot</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/init/index.html">Weight Initializations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nn/init/uniform.html">nn.init.uniform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/init/normal.html">nn.init.normal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/init/constant.html">nn.init.constant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/init/xavier_uniform.html">nn.init.xavier_uniform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/init/xavier_normal.html">nn.init.xavier_normal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/init/kaiming_uniform.html">nn.init.kaiming_uniform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/init/kaiming_normal.html">nn.init.kaiming_normal</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/modules/index.html">Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/linear/index.html">Linear Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/linear/Identity.html">nn.Identity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/linear/Flatten.html">nn.Flatten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/linear/Linear.html">nn.Linear</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/linear/Bilinear.html">nn.Bilinear</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/conv/index.html">Convolution Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/conv/Unfold.html">nn.Unfold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/conv/Conv1d.html">nn.Conv1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/conv/Conv2d.html">nn.Conv2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/conv/Conv3d.html">nn.Conv3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/conv/ConvTranspose1d.html">nn.ConvTranspose1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/conv/ConvTranspose2d.html">nn.ConvTranspose2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/conv/ConvTranspose3d.html">nn.ConvTranspose3d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/activation/index.html">Activation Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/ReLU.html">nn.ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/ReLU6.html">nn.ReLU6</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/LeakyReLU.html">nn.LeakyReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/ELU.html">nn.ELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/SELU.html">nn.SELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/GELU.html">nn.GELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/Sigmoid.html">nn.Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/HardSigmoid.html">nn.HardSigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/Tanh.html">nn.Tanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/Softmax.html">nn.Softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/Swish.html">nn.Swish</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/HardSwish.html">nn.HardSwish</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/activation/Mish.html">nn.Mish</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/pool/index.html">Pooling Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AvgPool1d.html">nn.AvgPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AvgPool2d.html">nn.AvgPool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AvgPool3d.html">nn.AvgPool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/MaxPool1d.html">nn.MaxPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/MaxPool2d.html">nn.MaxPool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/MaxPool3d.html">nn.MaxPool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AdaptiveAvgPool1d.html">nn.AdaptiveAvgPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AdaptiveAvgPool2d.html">nn.AdaptiveAvgPool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AdaptiveAvgPool3d.html">nn.AdaptiveAvgPool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AdaptiveMaxPool1d.html">nn.AdaptiveMaxPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AdaptiveMaxPool2d.html">nn.AdaptiveMaxPool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/pool/AdaptiveMaxPool3d.html">nn.AdaptiveMaxPool3d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/norm/index.html">Normalization Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/BatchNorm1d.html">nn.BatchNorm1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/BatchNorm2d.html">nn.BatchNorm2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/BatchNorm3d.html">nn.BatchNorm3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/InstanceNorm1d.html">nn.InstanceNorm1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/InstanceNorm2d.html">nn.InstanceNorm2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/InstanceNorm3d.html">nn.InstanceNorm3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/LayerNorm.html">nn.LayerNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/GroupNorm.html">nn.GroupNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/norm/GlobalResponseNorm.html">nn.GlobalResponseNorm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/drop/index.html">Dropout Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/drop/Dropout.html">nn.Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/drop/Dropout1d.html">nn.Dropout1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/drop/Dropout2d.html">nn.Dropout2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/drop/Dropout3d.html">nn.Dropout3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/drop/AlphaDropout.html">nn.AlphaDropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/drop/DropBlock.html">nn.DropBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/drop/DropPath.html">nn.DropPath</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/loss/index.html">Loss Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/loss/MSELoss.html">nn.MSELoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/loss/BCELoss.html">nn.BCELoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/loss/BCEWithLogitsLoss.html">nn.BCEWithLogitsLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/loss/CrossEntropyLoss.html">nn.CrossEntropyLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/loss/NLLLoss.html">nn.NLLLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/loss/HuberLoss.html">nn.HuberLoss</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/vision/index.html">Vision Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/vision/Upsample.html">nn.Upsample</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/sparse/index.html">Sparse Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/sparse/Embedding.html">nn.Embedding</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/rnn/index.html">Recurrent Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/rnn/RNNBase.html">nn.RNNBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/rnn/RNN.html">nn.RNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/rnn/LSTM.html">nn.LSTM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/rnn/GRU.html">nn.GRU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/rnn/RNNCell.html">nn.RNNCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/rnn/LSTMCell.html">nn.LSTMCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/rnn/GRUCell.html">nn.GRUCell</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/attention/index.html">Attention Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/attention/ScaledDotProductAttention.html">nn.ScaledDotProductAttention</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/attention/MultiHeadAttention.html">nn.MultiHeadAttention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/transformer/index.html">Transformer Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/transformer/TransformerEncoderLayer.html">nn.TransformerEncoderLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/transformer/TransformerDecoderLayer.html">nn.TransformerDecoderLayer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/transformer/TransformerEncoder.html">nn.TransformerEncoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/transformer/TransformerDecoder.html">nn.TransformerDecoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/transformer/Transformer.html">nn.Transformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/modules/einops/index.html">Einops Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/modules/einops/Rearrange.html">nn.Rearrange</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/fused/index.html">Fused Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/ConvBNReLU1d.html">nn.ConvBNReLU1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/ConvBNReLU2d.html">nn.ConvBNReLU2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/ConvBNReLU3d.html">nn.ConvBNReLU3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/DepthSeparableConv1d.html">nn.DepthSeparableConv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/DepthSeparableConv2d.html">nn.DepthSeparableConv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/DepthSeparableConv3d.html">nn.DepthSeparableConv3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/SEModule.html">nn.SEModule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/fused/SelectiveKernel.html">nn.SelectiveKernel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/containers/index.html">Containers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nn/containers/Sequential.html">nn.Sequential</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/containers/ModuleList.html">nn.ModuleList</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/containers/ModuleDict.html">nn.ModuleDict</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/containers/ParameterList.html">nn.ParameterList</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/containers/ParameterDict.html">nn.ParameterDict</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/caches/index.html">Caches</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nn/caches/Cache.html">nn.Cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/caches/KVCache.html">nn.KVCache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/caches/EncoderDecoderCache.html">nn.EncoderDecoderCache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/caches/DynamicKVCache.html">nn.DynamicKVCache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/caches/StaticKVCache.html">nn.StaticKVCache</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../nn/utilities/index.html">Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nn/utilities/grad_norm.html">nn.utils.grad_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/utilities/get_total_norm.html">nn.utils.get_total_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/utilities/clip_grad_norm.html">nn.utils.clip_grad_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/utilities/clip_grad_value.html">nn.utils.clip_grad_value</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/utilities/apply_chunking_to_forward.html">nn.utils.apply_chunking_to_forward</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nn/utilities/rnn/index.html">RNN Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../nn/utilities/rnn/pad_sequence.html">nn.utils.rnn.pad_sequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/utilities/rnn/PackedSequence.html">nn.utils.rnn.PackedSequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/utilities/rnn/pack_padded_sequence.html">nn.utils.rnn.pack_padded_sequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/utilities/rnn/pad_packed_sequence.html">nn.utils.rnn.pad_packed_sequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/utilities/rnn/pack_sequence.html">nn.utils.rnn.pack_sequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nn/utilities/rnn/unpack_sequence.html">nn.utils.rnn.unpack_sequence</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../optim/optim.html">lucid.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim/Optimizer.html">optim.Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim/lr_scheduler.html">optim.lr_scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim/optimizers/index.html">Optimizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/SGD.html">optim.SGD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/ASGD.html">optim.ASGD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/RMSprop.html">optim.RMSprop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/Rprop.html">optim.Rprop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/Adam.html">optim.Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/AdamW.html">optim.AdamW</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/NAdam.html">optim.NAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/RAdam.html">optim.RAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/Adamax.html">optim.Adamax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/Adagrad.html">optim.Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/optimizers/Adadelta.html">optim.Adadelta</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../optim/lr_scheduler/index.html">LR Schedulers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/LRScheduler.html">lr_scheduler.LRScheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/LambdaLR.html">lr_scheduler.LambdaLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/StepLR.html">lr_scheduler.StepLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/MultiStepLR.html">lr_scheduler.MultiStepLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/ExponentialLR.html">lr_scheduler.ExponentialLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/CosineAnnealingLR.html">lr_scheduler.CosineAnnealingLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/ReduceLROnPlateau.html">lr_scheduler.ReduceLROnPlateau</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/CyclicLR.html">lr_scheduler.CyclicLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optim/lr_scheduler/NoamScheduler.html">lr_scheduler.NoamScheduler</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../data/data.html">lucid.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/Dataset.html">data.Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/Subset.html">data.Subset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/TensorDataset.html">data.TensorDataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/ConcatDataset.html">data.ConcatDataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/DataLoader.html">data.DataLoader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data/tokenizers/index.html">Tokenizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../data/tokenizers/Tokenizer.html">tokenizers.Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data/tokenizers/WordPieceTokenizer.html">WordPieceTokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data/tokenizers/WordPieceTokenizerFast.html">WordPieceTokenizerFast</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../data/utilities/index.html">Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../data/utilities/random_split.html">data.random_split</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../datasets/datasets.html">lucid.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../datasets/image/index.html">Image Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/image/MNIST.html">MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/image/FashionMNIST.html">FashionMNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/image/CIFAR10.html">CIFAR10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/image/CIFAR100.html">CIFAR100</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../models.html">lucid.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mixins/index.html">Base Mixins</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../mixins/PreTrainedModelMixin.html">PreTrainedModelMixin</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Image Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lenet/LeNet.html">LeNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lenet/lenet_1.html">lenet_1</a></li>
<li class="toctree-l3"><a class="reference internal" href="lenet/lenet_4.html">lenet_4</a></li>
<li class="toctree-l3"><a class="reference internal" href="lenet/lenet_5.html">lenet_5</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="alex/AlexNet_.html">AlexNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="alex/alexnet.html">alexnet</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="zfnet/ZFNet_.html">ZFNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="zfnet/zfnet.html">zfnet</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="vgg/VGGNet.html">VGGNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="vgg/vggnet_11.html">vggnet_11</a></li>
<li class="toctree-l3"><a class="reference internal" href="vgg/vggnet_13.html">vggnet_13</a></li>
<li class="toctree-l3"><a class="reference internal" href="vgg/vggnet_16.html">vggnet_16</a></li>
<li class="toctree-l3"><a class="reference internal" href="vgg/vggnet_19.html">vggnet_19</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="inception/Inception.html">Inception</a><ul>
<li class="toctree-l3"><a class="reference internal" href="inception/inception_v1.html">inception_v1</a></li>
<li class="toctree-l3"><a class="reference internal" href="inception/inception_v3.html">inception_v3</a></li>
<li class="toctree-l3"><a class="reference internal" href="inception/inception_v4.html">inception_v4</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="inception_res/InceptionResNet.html">Inception-ResNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="inception_res/inception_resnet_v1.html">inception_resnet_v1</a></li>
<li class="toctree-l3"><a class="reference internal" href="inception_res/inception_resnet_v2.html">inception_resnet_v2</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="resnet/ResNet.html">ResNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_18.html">resnet_18</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_34.html">resnet_34</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_50.html">resnet_50</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_101.html">resnet_101</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_152.html">resnet_152</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_200.html">resnet_200</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_269.html">resnet_269</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/resnet_1001.html">resnet_1001</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/wide_resnet_50.html">wide_resnet_50</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnet/wide_resnet_101.html">wide_resnet_101</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="resnext/ResNeXt.html">ResNeXt</a><ul>
<li class="toctree-l3"><a class="reference internal" href="resnext/resnext_50_32x4d.html">resnext_50_32x4d</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnext/resnext_101_32x4d.html">resnext_101_32x4d</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnext/resnext_101_32x8d.html">resnext_101_32x8d</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnext/resnext_101_32x16d.html">resnext_101_32x16d</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnext/resnext_101_32x32d.html">resnext_101_32x32d</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnext/resnext_101_64x4d.html">resnext_101_64x4d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="resnest/ResNeSt.html">ResNeSt</a><ul>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_14.html">resnest_14</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_26.html">resnest_26</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_50.html">resnest_50</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_101.html">resnest_101</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_200.html">resnest_200</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_269.html">resnest_269</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_50_4s2x40d.html">resnest_50_4s2x40d</a></li>
<li class="toctree-l3"><a class="reference internal" href="resnest/resnest_50_1s4x24d.html">resnest_50_1s4x24d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="senet/SENet.html">SENet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnet_18.html">se_resnet_18</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnet_34.html">se_resnet_34</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnet_50.html">se_resnet_50</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnet_101.html">se_resnet_101</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnet_152.html">se_resnet_152</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnext_50_32x4d.html">se_resnext_50_32x4d</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnext_101_32x4d.html">se_resnext_101_32x4d</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnext_101_32x8d.html">se_resnext_101_32x8d</a></li>
<li class="toctree-l3"><a class="reference internal" href="senet/se_resnext_101_64x4d.html">se_resnext_101_64x4d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sknet/SKNet.html">SKNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sknet/sk_resnet_18.html">sk_resnet_18</a></li>
<li class="toctree-l3"><a class="reference internal" href="sknet/sk_resnet_34.html">sk_resnet_34</a></li>
<li class="toctree-l3"><a class="reference internal" href="sknet/sk_resnet_50.html">sk_resnet_50</a></li>
<li class="toctree-l3"><a class="reference internal" href="sknet/sk_resnext_50_32x4d.html">sk_resnext_50_32x4d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dense/DenseNet.html">DenseNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dense/densenet_121.html">densenet_121</a></li>
<li class="toctree-l3"><a class="reference internal" href="dense/densenet_169.html">densenet_169</a></li>
<li class="toctree-l3"><a class="reference internal" href="dense/densenet_201.html">densenet_201</a></li>
<li class="toctree-l3"><a class="reference internal" href="dense/densenet_264.html">densenet_264</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="xception/Xception_.html">Xception</a><ul>
<li class="toctree-l3"><a class="reference internal" href="xception/xception.html">xception</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mobile/MobileNet_.html">MobileNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet.html">mobilenet</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mobile/MobileNet_V2_.html">MobileNet-v2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v2.html">mobilenet_v2</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mobile/MobileNet_V3.html">MobileNet-v3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v3_small.html">mobilenet_v3_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v3_large.html">mobilenet_v3_large</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mobile/MobileNet_V4.html">MobileNet-v4</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v4_conv_small.html">mobilenet_v4_conv_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v4_conv_medium.html">mobilenet_v4_conv_medium</a></li>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v4_conv_large.html">mobilenet_v4_conv_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v4_hybrid_medium.html">mobilenet_v4_hybrid_medium</a></li>
<li class="toctree-l3"><a class="reference internal" href="mobile/mobilenet_v4_hybrid_large.html">mobilenet_v4_hybrid_large</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="efficient/EfficientNet.html">EfficientNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b0.html">efficientnet_b0</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b1.html">efficientnet_b1</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b2.html">efficientnet_b2</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b3.html">efficientnet_b3</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b4.html">efficientnet_b4</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b5.html">efficientnet_b5</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b6.html">efficientnet_b6</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_b7.html">efficientnet_b7</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="efficient/EfficientNet_V2.html">EfficientNet-v2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_v2_s.html">efficientnet_v2_s</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_v2_m.html">efficientnet_v2_m</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_v2_l.html">efficientnet_v2_l</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficient/efficientnet_v2_xl.html">efficientnet_v2_xl</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="convnext/ConvNeXt.html">ConvNeXt</a><ul>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_tiny.html">convnext_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_small.html">convnext_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_base.html">convnext_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_large.html">convnext_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_xlarge.html">convnext_xlarge</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="convnext/ConvNeXt_V2.html">ConvNeXt-v2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_atto.html">convnext_v2_atto</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_femto.html">convnext_v2_femto</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_pico.html">convnext_v2_pico</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_nano.html">convnext_v2_nano</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_tiny.html">convnext_v2_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_base.html">convnext_v2_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_large.html">convnext_v2_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="convnext/convnext_v2_huge.html">convnext_v2_huge</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="inception_next/InceptionNeXt.html">InceptionNeXt</a><ul>
<li class="toctree-l3"><a class="reference internal" href="inception_next/inception_next_atto.html">inception_next_atto</a></li>
<li class="toctree-l3"><a class="reference internal" href="inception_next/inception_next_tiny.html">inception_next_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="inception_next/inception_next_small.html">inception_next_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="inception_next/inception_next_base.html">inception_next_base</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="coatnet/CoAtNet.html">CoAtNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_0.html">coatnet_0</a></li>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_1.html">coatnet_1</a></li>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_2.html">coatnet_2</a></li>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_3.html">coatnet_3</a></li>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_4.html">coatnet_4</a></li>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_5.html">coatnet_5</a></li>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_6.html">coatnet_6</a></li>
<li class="toctree-l3"><a class="reference internal" href="coatnet/coatnet_7.html">coatnet_7</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cspnet/CSPNet.html">CSPNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cspnet/csp_resnet_50.html">csp_resnet_50</a></li>
<li class="toctree-l3"><a class="reference internal" href="cspnet/csp_resnext_50_32x4d.html">csp_resnext_50_32x4d</a></li>
<li class="toctree-l3"><a class="reference internal" href="cspnet/csp_darknet_53.html">csp_darknet_53</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="vit/ViT.html">ViT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="vit/vit_tiny.html">vit_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="vit/vit_small.html">vit_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="vit/vit_base.html">vit_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="vit/vit_large.html">vit_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="vit/vit_huge.html">vit_huge</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="swin/SwinTransformer.html">Swin Transformer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_tiny.html">swin_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_small.html">swin_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_base.html">swin_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_large.html">swin_large</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="swin/SwinTransformer_V2.html">Swin Transformer-v2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_v2_tiny.html">swin_v2_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_v2_small.html">swin_v2_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_v2_base.html">swin_v2_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_v2_large.html">swin_v2_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_v2_huge.html">swin_v2_huge</a></li>
<li class="toctree-l3"><a class="reference internal" href="swin/swin_v2_giant.html">swin_v2_giant</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cvt/CvT.html">CvT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cvt/cvt_13.html">cvt_13</a></li>
<li class="toctree-l3"><a class="reference internal" href="cvt/cvt_21.html">cvt_21</a></li>
<li class="toctree-l3"><a class="reference internal" href="cvt/cvt_w24.html">cvt_w24</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pvt/PVT.html">PVT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_tiny.html">pvt_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_small.html">pvt_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_medium.html">pvt_medium</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_large.html">pvt_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_huge.html">pvt_huge</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pvt/PVT_V2.html">PVT-v2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_v2_b0.html">pvt_v2_b0</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_v2_b1.html">pvt_v2_b1</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_v2_b2.html">pvt_v2_b2</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_v2_b2_li.html">pvt_v2_b2_li</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_v2_b3.html">pvt_v2_b3</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_v2_b4.html">pvt_v2_b4</a></li>
<li class="toctree-l3"><a class="reference internal" href="pvt/pvt_v2_b5.html">pvt_v2_b5</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="crossvit/CrossViT.html">CrossViT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_tiny.html">crossvit_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_small.html">crossvit_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_base.html">crossvit_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_9.html">crossvit_9</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_15.html">crossvit_15</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_18.html">crossvit_18</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_9_dagger.html">crossvit_9_dagger</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_15_dagger.html">crossvit_15_dagger</a></li>
<li class="toctree-l3"><a class="reference internal" href="crossvit/crossvit_18_dagger.html">crossvit_18_dagger</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="maxvit/MaxViT.html">MaxViT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="maxvit/maxvit_tiny.html">maxvit_tiny</a></li>
<li class="toctree-l3"><a class="reference internal" href="maxvit/maxvit_small.html">maxvit_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="maxvit/maxvit_base.html">maxvit_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="maxvit/maxvit_large.html">maxvit_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="maxvit/maxvit_xlarge.html">maxvit_xlarge</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="efficientformer/EfficientFormer.html">EfficientFormer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="efficientformer/efficientformer_l1.html">efficientformer_l1</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficientformer/efficientformer_l3.html">efficientformer_l3</a></li>
<li class="toctree-l3"><a class="reference internal" href="efficientformer/efficientformer_l7.html">efficientformer_l7</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../imggen/index.html">Image Generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../imggen/autoencoder/VAE.html">VAE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../imggen/diffusion/DDPM.html">DDPM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../imggen/diffusion/NCSN.html">NCSN</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../objdet/index.html">Object Detection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../objdet/utilities/index.html">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/iou.html">util.iou</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/nms.html">util.nms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/bbox_to_delta.html">util.bbox_to_delta</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/apply_deltas.html">util.apply_deltas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/clip_boxes.html">util.clip_boxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/SelectiveSearch.html">util.SelectiveSearch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/ROIAlign.html">util.ROIAlign</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/MultiScaleROIAlign.html">util.MultiScaleROIAlign</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/utilities/FPN.html">util.FPN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../objdet/rcnn/RCNN.html">R-CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../objdet/rcnn/FastRCNN.html">Fast R-CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../objdet/faster_rcnn/FasterRCNN.html">Faster R-CNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../objdet/faster_rcnn/faster_rcnn_resnet_50_fpn.html">faster_rcnn_resnet_50_fpn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/faster_rcnn/faster_rcnn_resnet_101_fpn.html">faster_rcnn_resnet_101_fpn</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../objdet/yolo/index.html">YOLO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../objdet/yolo/v1/YOLO_V1_.html">YOLO-v1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../objdet/yolo/v1/yolo_v1.html">yolo_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../objdet/yolo/v1/yolo_v1_tiny.html">yolo_v1_tiny</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/yolo/v2/YOLO_V2_.html">YOLO-v2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../objdet/yolo/v2/yolo_v2.html">yolo_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../objdet/yolo/v2/yolo_v2_tiny.html">yolo_v2_tiny</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/yolo/v3/YOLO_V3_.html">YOLO-v3</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../objdet/yolo/v3/yolo_v3.html">yolo_v3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../objdet/yolo/v3/yolo_v3_tiny.html">yolo_v3_tiny</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/yolo/v4/YOLO_V4_.html">YOLO-v4</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../objdet/yolo/v4/yolo_v4.html">yolo_v4</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../objdet/efficientdet/EfficientDet.html">EfficientDet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d0.html">efficientdet_d0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d1.html">efficientdet_d1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d2.html">efficientdet_d2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d3.html">efficientdet_d3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d4.html">efficientdet_d4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d5.html">efficientdet_d5</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d6.html">efficientdet_d6</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/efficientdet/efficientdet_d7.html">efficientdet_d7</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../objdet/detr/DETR.html">DETR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../objdet/detr/detr_r50.html">detr_r50</a></li>
<li class="toctree-l3"><a class="reference internal" href="../objdet/detr/detr_r101.html">detr_r101</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../seq2seq/index.html">Sequence-to-Sequence</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../seq2seq/transformer/Transformer.html">Transformer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../seq2seq/transformer/transformer_base.html">transformer_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seq2seq/transformer/transformer_big.html">transformer_big</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../seqclf/index.html">Sequence Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../seqclf/bert/BERT.html">BERT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTConfig.html">BERTConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTForPreTraining.html">BERTForPreTraining</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTForMaskedLM.html">BERTForMaskedLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTForCausalLM.html">BERTForCausalLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTForNextSentencePrediction.html">BERTForNextSentencePrediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTForSequenceClassification.html">BERTForSequenceClassification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTForTokenClassification.html">BERTForTokenClassification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/BERTForQuestionAnswering.html">BERTForQuestionAnswering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_pre_training_base.html">bert_for_pre_training_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_pre_training_large.html">bert_for_pre_training_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_masked_lm_base.html">bert_for_masked_lm_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_masked_lm_large.html">bert_for_masked_lm_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_causal_lm_base.html">bert_for_causal_lm_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_causal_lm_large.html">bert_for_causal_lm_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_next_sentence_prediction_base.html">bert_for_next_sentence_prediction_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_next_sentence_prediction_large.html">bert_for_next_sentence_prediction_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_sequence_classification_base.html">bert_for_sequence_classification_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_sequence_classification_large.html">bert_for_sequence_classification_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_token_classification_base.html">bert_for_token_classification_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_token_classification_large.html">bert_for_token_classification_large</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_question_answering_base.html">bert_for_question_answering_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../seqclf/bert/bert_for_question_answering_large.html">bert_for_question_answering_large</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Weights</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../weights/weights.html">lucid.weights</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../weights/list.html">Pre-Trained Weights</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Transformation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../transforms/transforms.html">lucid.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transforms/Compose.html">transforms.Compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transforms/ToTensor.html">transforms.ToTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transforms/image/index.html">Image Transforms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/Normalize.html">transforms.Normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/Resize.html">transforms.Resize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/RandomHorizontalFlip.html">transforms.RandomHorizontalFlip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/RandomVerticalFlip.html">transforms.RandomVerticalFlip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/RandomCrop.html">transforms.RandomCrop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/CenterCrop.html">transforms.CenterCrop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/RandomRotation.html">transforms.RandomRotation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transforms/image/RandomGrayscale.html">transforms.RandomGrayscale</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Visualization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../visual/visual.html">lucid.visual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../visual/Mermaid.html">Mermaid Charts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../visual/build_tensor_mermaid_chart.html">visual.build_tensor_mermaid_chart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../visual/build_module_mermaid_chart.html">visual.build_module_mermaid_chart</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Porting</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../porting/save.html">lucid.save</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../porting/load.html">lucid.load</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">Others</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../others/Numeric.html">lucid.Numeric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../others/no_grad.html">lucid.no_grad</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../others/grad_enabled.html">lucid.grad_enabled</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../others/count_flops.html">lucid.count_flops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../others/newaxis.html">lucid.newaxis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../others/register_model.html">lucid.register_model</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div class="localtoc"><h3>On this page</h3><ul>
<li><a class="reference internal" href="#lenet">LeNet</a></li>
<li><a class="reference internal" href="#alexnet">AlexNet</a></li>
<li><a class="reference internal" href="#zfnet">ZFNet</a></li>
<li><a class="reference internal" href="#vggnet">VGGNet</a></li>
<li><a class="reference internal" href="#inception">Inception</a></li>
<li><a class="reference internal" href="#inception-resnet">Inception-ResNet</a></li>
<li><a class="reference internal" href="#resnet">ResNet</a></li>
<li><a class="reference internal" href="#resnext">ResNeXt</a></li>
<li><a class="reference internal" href="#senet">SENet</a></li>
<li><a class="reference internal" href="#sknet">SKNet</a></li>
<li><a class="reference internal" href="#densenet">DenseNet</a></li>
<li><a class="reference internal" href="#xception">Xception</a></li>
<li><a class="reference internal" href="#mobilenet">MobileNet</a></li>
<li><a class="reference internal" href="#efficientnet">EfficientNet</a></li>
<li><a class="reference internal" href="#resnest">ResNeSt</a></li>
<li><a class="reference internal" href="#convnext">ConvNeXt</a></li>
<li><a class="reference internal" href="#inceptionnext">InceptionNeXt</a></li>
<li><a class="reference internal" href="#coatnet">CoAtNet</a></li>
<li><a class="reference internal" href="#cspnet">CSPNet</a></li>
<li><a class="reference internal" href="#visual-transformer-vit">Visual Transformer (ViT)</a></li>
<li><a class="reference internal" href="#swin-transformer">Swin Transformer</a></li>
<li><a class="reference internal" href="#convolutional-transformer-cvt">Convolutional Transformer (CvT)</a></li>
<li><a class="reference internal" href="#pyramid-vision-transformer-pvt">Pyramid Vision Transformer (PVT)</a></li>
<li><a class="reference internal" href="#crossvit">CrossViT</a></li>
<li><a class="reference internal" href="#maxvit">MaxViT</a></li>
<li><a class="reference internal" href="#efficientformer">EfficientFormer</a></li>
</ul>
</div><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../index.html"><span itemprop="name">Lucid</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">Image Classification</strong>
        <meta itemprop="position" content="2" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="relative min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
  <div class="copy-page-wrapper relative pb-4 lg:absolute lg:top-8 lg:right-6 xl:right-12">
  <div id="copy-page-trigger">
    <button
      type="button"
      class="js-copy px-3 py-1 inline-flex items-center gap-1"
      data-url="https://chanlumerico.github.io/lucid/_sources/models/imgclf/index.rst.txt"
    >
      <i class="i-lucide" data-icon="copy"></i>
      <span>Copy page</span>
    </button>
    <button class="js-menu px-2 py-1" type="button" aria-label="More actions"
      aria-haspopup="menu" aria-expanded="false" aria-controls="copy-page-content">
      <i class="i-lucide chevron-down"></i>
    </button>
  </div>
  <div id="copy-page-content" role="menu" aria-orientation="vertical" aria-hidden="true">
    <div role="presentation">
      <div class="flex flex-col" role="group">
        <button class="js-copy" type="button" role="menuitem"
          data-url="https://chanlumerico.github.io/lucid/_sources/models/imgclf/index.rst.txt">
          <span class="iconify-icon">
            <i class="i-lucide" data-icon="copy"></i>
          </span>
          <span>Copy page</span>
        </button>
        <a role="menuitem" href="https://chanlumerico.github.io/lucid/_sources/models/imgclf/index.rst.txt" target="_blank" rel="nofollow"><iconify-icon icon="bi:code-slash"></iconify-icon>
            <span>View Source</span></a><a role="menuitem" href="https://chatgpt.com/?hints=search&q=Read%20https%3A//chanlumerico.github.io/lucid/_sources/models/imgclf/index.rst.txt%20so%20I%20can%20ask%20questions%20about%20it." target="_blank" rel="nofollow">
          <iconify-icon icon="bi:openai"></iconify-icon>
          <span>Open in ChatGPT</span>
        </a><a role="menuitem" href="https://claude.ai/new?q=Read%20https%3A//chanlumerico.github.io/lucid/_sources/models/imgclf/index.rst.txt%20so%20I%20can%20ask%20questions%20about%20it." target="_blank" rel="nofollow">
          <iconify-icon icon="bi:claude"></iconify-icon>
          <span>Open in Claude</span>
        </a></div>
    </div>
  </div>
</div><article class="yue" role="main">
          <section id="image-classification">
<h1>Image Classification<a class="headerlink" href="#image-classification" title="Link to this heading"></a></h1>
<div class="toctree-wrapper compound">
</div>
<section id="lenet">
<h2>LeNet<a class="headerlink" href="#lenet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>LeNet is a pioneering CNN by Yann LeCun for digit recognition,
combining convolutional, pooling, and fully connected layers.
It introduced concepts like weight sharing and local receptive fields,
shaping modern CNNs.</p>
<blockquote>
<div><p>Lecun, Yann, et al. Gradient-Based Learning Applied to Document Recognition.
<em>Proceedings of the IEEE</em>, vol. 86, no. 11, Nov. 1998, pp. 2278-2324.
doi:10.1109/5.726791.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>LeNet-1</p></td>
<td><p><a class="reference external" href="lenet/lenet_1">lenet_1</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,1,28,28)\)</span></p></td>
<td><p>3,246</p></td>
<td><p>167.13K</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>LeNet-4</p></td>
<td><p><a class="reference external" href="lenet/lenet_4">lenet_4</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,1,28,28)\)</span></p></td>
<td><p>18,378</p></td>
<td><p>182.93K</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>LeNet-5</p></td>
<td><p><a class="reference external" href="lenet/lenet_5">lenet_5</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,1,32,32)\)</span></p></td>
<td><p>61,706</p></td>
<td><p>481.49K</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="alexnet">
<h2>AlexNet<a class="headerlink" href="#alexnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>AlexNet is a pioneering convolutional neural network introduced in 2012,
known for its deep architecture and use of ReLU activations, dropout, and GPU acceleration.
It achieved groundbreaking performance in the ImageNet Large Scale Visual Recognition
Challenge (ILSVRC) in 2012, popularizing deep learning for computer vision.</p>
<blockquote>
<div><p>Krizhevsky, Alex, et al. ImageNet Classification with Deep Convolutional Neural Networks.
<em>Advances in Neural Information Processing Systems</em>, vol. 25, 2012, pp. 1097-1105.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AlexNet</p></td>
<td><p><a class="reference external" href="alex/alexnet">alexnet</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>61,100,840</p></td>
<td><p>715.21M</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="zfnet">
<h2>ZFNet<a class="headerlink" href="#zfnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>ZFNet (Zeiler and Fergus Net) is a convolutional neural network that improved upon
AlexNet by using smaller convolutional filters and visualizing learned features to
better understand network behavior. It achieved state-of-the-art results in object
recognition and provided insights into deep learning interpretability.</p>
<blockquote>
<div><p>Zeiler, Matthew D., and Rob Fergus. Visualizing and Understanding Convolutional Networks.
<em>European Conference on Computer Vision (ECCV)</em>, Springer, Cham, 2014, pp. 818-833.
doi:10.1007/978-3-319-10590-1_53.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ZFNet</p></td>
<td><p><a class="reference external" href="zfnet/zfnet">zfnet</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>62,357,608</p></td>
<td><p>1.20B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="vggnet">
<h2>VGGNet<a class="headerlink" href="#vggnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>VGGNet is a deep convolutional neural network known for its simplicity and use of
small 3x3 convolutional filters, which significantly improved object recognition accuracy.</p>
<blockquote>
<div><p>Simonyan, Karen, and Andrew Zisserman. Very Deep Convolutional Networks for
Large-Scale Image Recognition. <em>arXiv preprint arXiv:1409.1556</em>, 2014.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>VGGNet-11</p></td>
<td><p><a class="reference external" href="vgg/vggnet_11">vggnet_11</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>132,863,336</p></td>
<td><p>7.62B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>VGGNet-13</p></td>
<td><p><a class="reference external" href="vgg/vggnet_13">vggnet_13</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>133,047,848</p></td>
<td><p>11.33B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>VGGNet-16</p></td>
<td><p><a class="reference external" href="vgg/vggnet_16">vggnet_16</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>138,357,544</p></td>
<td><p>15.50B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>VGGNet-19</p></td>
<td><p><a class="reference external" href="vgg/vggnet_19">vggnet_19</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>143,667,240</p></td>
<td><p>19.66B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inception">
<h2>Inception<a class="headerlink" href="#inception" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>The Inception architecture, introduced in the GoogLeNet model, is a deep convolutional
neural network designed for efficient feature extraction using parallel convolutional and
pooling branches, reducing computational cost. It achieves this by combining multi-scale
feature processing within each module, making it highly effective for image classification
tasks.</p>
<blockquote>
<div><p>Szegedy, Christian, et al. Going Deeper with Convolutions. <em>Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2015, pp. 1-9.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Inception-v1 (GoogLeNet)</p></td>
<td><p><a class="reference external" href="inception/inception_v1">inception_v1</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>13,393,352</p></td>
<td><p>1.62B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Inception-v3</p></td>
<td><p><a class="reference external" href="inception/inception_v3">inception_v3</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,299,299)\)</span></p></td>
<td><p>30,817,392</p></td>
<td><p>3.20B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Inception-v4</p></td>
<td><p><a class="reference external" href="inception/inception_v4">inception_v4</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,299,299)\)</span></p></td>
<td><p>40,586,984</p></td>
<td><p>5.75B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inception-resnet">
<h2>Inception-ResNet<a class="headerlink" href="#inception-resnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>The Inception-ResNet architecture builds upon the Inception model by integrating
residual connections, which improve gradient flow and training stability in very
deep networks. This combination of Inceptions multi-scale feature processing with
ResNets efficient backpropagation allows for a powerful and scalable design, suitable
for a wide range of image classification tasks.</p>
<blockquote>
<div><p>Szegedy, Christian, et al. Inception-v4, Inception-ResNet and the Impact of Residual
Connections on Learning. <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>,
2017, pp. 4278-4284.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Inception-ResNet-v1</p></td>
<td><p><a class="reference external" href="inception_res/inception_resnet_v1">inception_resnet_v1</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,299,299)\)</span></p></td>
<td><p>22,739,128</p></td>
<td><p>3.16B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Inception-ResNet-v2</p></td>
<td><p><a class="reference external" href="inception_res/inception_resnet_v2">inception_resnet_v2</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,299,299)\)</span></p></td>
<td><p>35,847,512</p></td>
<td><p>4.54B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="resnet">
<h2>ResNet<a class="headerlink" href="#resnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>ResNets (Residual Networks) are deep neural network architectures that use skip
connections (residual connections) to alleviate the vanishing gradient problem,
enabling the training of extremely deep models. They revolutionized deep learning
by introducing identity mappings, allowing efficient backpropagation and improved
accuracy in tasks like image classification and object detection.</p>
<blockquote>
<div><p>He, Kaiming, et al. Deep Residual Learning for Image Recognition.
<em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2016, pp. 770-778.</p>
<p>He, Kaiming, et al. Identity Mappings in Deep Residual Networks.
<em>European Conference on Computer Vision (ECCV)</em>, Springer, 2016, pp. 630-645.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ResNet-18</p></td>
<td><p><a class="reference external" href="resnet/resnet_18">resnet_18</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>11,689,512</p></td>
<td><p>1.84B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNet-34</p></td>
<td><p><a class="reference external" href="resnet/resnet_34">resnet_34</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>21,797,672</p></td>
<td><p>3.70B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNet-50</p></td>
<td><p><a class="reference external" href="resnet/resnet_50">resnet_50</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>25,557,032</p></td>
<td><p>4.20B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNet-101</p></td>
<td><p><a class="reference external" href="resnet/resnet_101">resnet_101</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>44,549,160</p></td>
<td><p>7.97B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNet-152</p></td>
<td><p><a class="reference external" href="resnet/resnet_152">resnet_152</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>60,192,808</p></td>
<td><p>11.75B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNet-200</p></td>
<td><p><a class="reference external" href="resnet/resnet_200">resnet_200</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>64,669,864</p></td>
<td><p>15.35B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNet-269</p></td>
<td><p><a class="reference external" href="resnet/resnet_269">resnet_269</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>102,069,416</p></td>
<td><p>20.46B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNet-1001</p></td>
<td><p><a class="reference external" href="resnet/resnet_1001">resnet_1001</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>149,071,016</p></td>
<td><p>43.94B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Wide-ResNet-50</p></td>
<td><p><a class="reference external" href="resnet/wide_resnet_50">wide_resnet_50</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>78,973,224</p></td>
<td><p>11.55B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Wide-ResNet-101</p></td>
<td><p><a class="reference external" href="resnet/wide_resnet_101">wide_resnet_101</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>126,886,696</p></td>
<td><p>22.97B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="resnext">
<h2>ResNeXt<a class="headerlink" href="#resnext" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>ResNeXt is an extension of the ResNet architecture that introduces a cardinality dimension
to the model, improving its performance and efficiency by allowing flexible aggregation of
transformations. ResNeXt builds on residual blocks by incorporating grouped convolutions,
enabling parallel pathways for feature learning.</p>
<blockquote>
<div><p>Xie, Saining, et al. Aggregated Residual Transformations for Deep Neural Networks.
<em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2017, pp. 5987-5995.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ResNeXt-50-32x4d</p></td>
<td><p><a class="reference external" href="resnext/resnext_50_32x4d">resnext_50_32x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>25,028,904</p></td>
<td><p>4.38B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNeXt-101-32x4d</p></td>
<td><p><a class="reference external" href="resnext/resnext_101_32x4d">resnext_101_32x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>44,177,704</p></td>
<td><p>8.19B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNeXt-101-32x8d</p></td>
<td><p><a class="reference external" href="resnext/resnext_101_32x8d">resnext_101_32x8d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>88,791,336</p></td>
<td><p>16.73B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNeXt-101-32x16d</p></td>
<td><p><a class="reference external" href="resnext/resnext_101_32x16d">resnext_101_32x16d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>194,026,792</p></td>
<td><p>36.68B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNeXt-101-32x32d</p></td>
<td><p><a class="reference external" href="resnext/resnext_101_32x32d">resnext_101_32x32d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>468,530,472</p></td>
<td><p>88.03B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNeXt-101-64x4d</p></td>
<td><p><a class="reference external" href="resnext/resnext_101_64x4d">resnext_101_64x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>83,455,272</p></td>
<td><p>15.78B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="senet">
<h2>SENet<a class="headerlink" href="#senet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>SENets (Squeeze-and-Excitation Networks) are deep neural network architectures that enhance t
he representational power of models by explicitly modeling channel interdependencies.
They introduce a novel squeeze-and-excitation block, which adaptively recalibrates channel-wise
feature responses.</p>
<blockquote>
<div><p>Hu, Jie, et al. Squeeze-and-Excitation Networks. <em>Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, 2018, pp. 7132-7141.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>SE-ResNet-18</p></td>
<td><p><a class="reference external" href="senet/se_resnet_18">se_resnet_18</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>11,778,592</p></td>
<td><p>1.84B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>SE-ResNet-34</p></td>
<td><p><a class="reference external" href="senet/se_resnet_34">se_resnet_34</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>21,958,868</p></td>
<td><p>3.71B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>SE-ResNet-50</p></td>
<td><p><a class="reference external" href="senet/se_resnet_50">se_resnet_50</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>28,088,024</p></td>
<td><p>4.22B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>SE-ResNet-101</p></td>
<td><p><a class="reference external" href="senet/se_resnet_101">se_resnet_101</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>49,326,872</p></td>
<td><p>8.00B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>SE-ResNet-152</p></td>
<td><p><a class="reference external" href="senet/se_resnet_152">se_resnet_152</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>66,821,848</p></td>
<td><p>11.80B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>SE-ResNeXt-50-32x4d</p></td>
<td><p><a class="reference external" href="senet/se_resnext_50_32x4d">se_resnext_50_32x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>27,559,896</p></td>
<td><p>4.40B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>SE-ResNeXt-101-32x4d</p></td>
<td><p><a class="reference external" href="senet/se_resnext_101_32x4d">se_resnext_101_32x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>48,955,416</p></td>
<td><p>8.22B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>SE-ResNeXt-101-32x8d</p></td>
<td><p><a class="reference external" href="senet/se_resnext_101_32x8d">se_resnext_101_32x8d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>93,569,048</p></td>
<td><p>16.77B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>SE-ResNeXt-101-64x4d</p></td>
<td><p><a class="reference external" href="senet/se_resnext_101_64x4d">se_resnext_101_64x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>88,232,984</p></td>
<td><p>15.81B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="sknet">
<h2>SKNet<a class="headerlink" href="#sknet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>SKNet (Selective Kernel Networks) is a deep learning architecture that enhances the
representational capacity of neural networks by enabling dynamic selection of kernel sizes
in convolutional layers. It introduces the concept of a selective kernel module,
which allows the network to adaptively choose the most appropriate receptive field for
each spatial location in an image, improving its ability to capture multi-scale features.</p>
<blockquote>
<div><p>Li, X., Zhang, S., &amp; Wang, X. (2019). Selective Kernel Networks. Proceedings of the
IEEE International Conference on Computer Vision (ICCV), 2019, pp. 510-519.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>SK-ResNet-18</p></td>
<td><p><a class="reference external" href="sknet/sk_resnet_18">sk_resnet_18</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>25,647,368</p></td>
<td><p>3.92B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>SK-ResNet-34</p></td>
<td><p><a class="reference external" href="sknet/sk_resnet_34">sk_resnet_34</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>45,895,512</p></td>
<td><p>7.64B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>SK-ResNet-50</p></td>
<td><p><a class="reference external" href="sknet/sk_resnet_50">sk_resnet_50</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>57,073,368</p></td>
<td><p>9.35B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>SK-ResNeXt-50-32x4d</p></td>
<td><p><a class="reference external" href="sknet/sk_resnext_50_32x4d">sk_resnext_50_32x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>29,274,760</p></td>
<td><p>5.04B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="densenet">
<h2>DenseNet<a class="headerlink" href="#densenet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>A deep learning architecture designed to improve the flow of information and gradients
in neural networks by introducing dense connectivity between layers. It leverages the
concept of dense blocks, where each layer is directly connected to all preceding layers
within the block. This dense connectivity pattern enhances feature reuse, reduces the number
of parameters, and improves the efficiency of gradient propagation during training.</p>
<blockquote>
<div><p>Huang, G., Liu, Z., Van Der Maaten, L., &amp; Weinberger, K. Q. (2017).
Densely Connected Convolutional Networks. <em>Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, 2017, pp. 4700-4708.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>DenseNet-121</p></td>
<td><p><a class="reference external" href="dense/densenet_121">densenet_121</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>7,978,856</p></td>
<td><p>2.99B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>DenseNet-169</p></td>
<td><p><a class="reference external" href="dense/densenet_169">densenet_169</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>14,149,480</p></td>
<td><p>3.55B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>DenseNet-201</p></td>
<td><p><a class="reference external" href="dense/densenet_201">densenet_201</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>20,013,928</p></td>
<td><p>4.54B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>DenseNet-264</p></td>
<td><p><a class="reference external" href="dense/densenet_264">densenet_264</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>33,337,704</p></td>
<td><p>6.09B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="xception">
<h2>Xception<a class="headerlink" href="#xception" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>A deep learning architecture that introduces depthwise separable convolutions
to enhance efficiency and accuracy in convolutional neural networks. It builds
on the idea that spatial and channel-wise information can be decoupled, significantly
reducing computational cost while maintaining performance.</p>
<blockquote>
<div><p>Chollet, F. (2017). Xception: Deep Learning with Depthwise Separable Convolutions.
<em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2017, pp. 1251-1258.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Xception</p></td>
<td><p><a class="reference external" href="xception/xception">xception</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>22,862,096</p></td>
<td><p>4.67B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="mobilenet">
<h2>MobileNet<a class="headerlink" href="#mobilenet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>A deep learning architecture that introduces depthwise separable convolutions
to enhance efficiency and accuracy in convolutional neural networks. It builds
on the idea that spatial and channel-wise information can be decoupled, significantly
reducing computational cost while maintaining performance.</p>
<blockquote>
<div><p><em>MobileNet</em></p>
<p>Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M.,
&amp; Adam, H. (2017). MobileNets: Efficient Convolutional Neural Networks for Mobile
Vision Applications. <em>arXiv preprint arXiv:1704.04861.</em></p>
<p><em>MobileNet-v2</em></p>
<p>Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., &amp; Chen, L.-C. (2018).
MobileNetV2: Inverted Residuals and Linear Bottlenecks. <em>Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp. 4510-4520.</p>
<p><em>MobileNet-v3</em></p>
<p>Howard, A., Sandler, M., Chu, G., Chen, L.-C., Chen, B., Tan, M., Wang, W., Zhu, Y.,
Pang, R., Vasudevan, V., Le, Q., &amp; Adam, H. (2019). Searching for MobileNetV3.
<em>Proceedings of the IEEE International Conference on Computer Vision (ICCV)</em>, pp. 1314-1324.</p>
<p><em>MobileNet-v4</em></p>
<p>Zhang, Wei, et al. MobileNet-v4: Advancing Efficiency for Mobile Vision.
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2024, pp. 5720-5730.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MobileNet</p></td>
<td><p><a class="reference external" href="mobile/mobilenet">mobilenet</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>4,232,008</p></td>
<td><p>584.08M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet-v2</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v2">mobilenet_v2</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>3,504,872</p></td>
<td><p>367.39M</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>MobileNet-v3-Small</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v3_small">mobilenet_v3_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>2,537,238</p></td>
<td><p>73.88M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet-v3-Large</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v3_large">mobilenet_v3_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>5,481,198</p></td>
<td><p>266.91M</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MobileNet-v4-Conv-Small</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v4_conv_small">mobilenet_v4_conv_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>3,774,024</p></td>
<td><p>265.15M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet-v4-Conv-Medium</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v4_conv_medium">mobilenet_v4_conv_medium</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>9,715,512</p></td>
<td><p>944.48M</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>MobileNet-v4-Conv-Large</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v4_conv_large">mobilenet_v4_conv_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>32,590,864</p></td>
<td><p>2.32B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet-v4-Hybrid-Medium</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v4_hybrid_medium">mobilenet_v4_hybrid_medium</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>11,070,136</p></td>
<td><p>1.09B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>MobileNet-v4-Hybrid-Large</p></td>
<td><p><a class="reference external" href="mobile/mobilenet_v4_hybrid_large">mobilenet_v4_hybrid_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>37,755,152</p></td>
<td><p>2.72B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="efficientnet">
<h2>EfficientNet<a class="headerlink" href="#efficientnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>EfficientNet is a family of convolutional neural networks optimized for
scalability and performance by systematically balancing network depth, width,
and resolution. It achieves state-of-the-art accuracy with fewer parameters and
computational resources compared to previous architectures.</p>
<blockquote>
<div><p><em>EfficientNet</em></p>
<p>Tan, Mingxing, and Quoc V. Le. EfficientNet: Rethinking Model Scaling for
Convolutional Neural Networks. <em>Proceedings of the 36th International Conference
on Machine Learning</em>, 2019, pp. 6105-6114.</p>
<p><em>EfficientNet-v2</em></p>
<p>Tan, Mingxing, and Quoc V. Le. EfficientNetV2: Smaller Models and Faster Training.
<em>Proceedings of the 38th International Conference on Machine Learning</em>, 2021,
pp. 10096-10106.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>EfficientNet-B0</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b0">efficientnet_b0</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>5,289,636</p></td>
<td><p>463.32M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-B1</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b1">efficientnet_b1</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,240,240)\)</span></p></td>
<td><p>7,795,560</p></td>
<td><p>849.06M</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-B2</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b2">efficientnet_b2</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,260,260)\)</span></p></td>
<td><p>9,111,370</p></td>
<td><p>1.20B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-B3</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b3">efficientnet_b3</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,300,300)\)</span></p></td>
<td><p>12,235,536</p></td>
<td><p>2.01B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-B4</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b4">efficientnet_b4</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,380,380)\)</span></p></td>
<td><p>19,344,640</p></td>
<td><p>4.63B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-B5</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b5">efficientnet_b5</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,456,456)\)</span></p></td>
<td><p>30,393,432</p></td>
<td><p>12.17B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-B6</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b6">efficientnet_b6</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,528,528)\)</span></p></td>
<td><p>43,046,128</p></td>
<td><p>21.34B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-B7</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_b7">efficientnet_b7</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,600,600)\)</span></p></td>
<td><p>66,355,448</p></td>
<td><p>40.31B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>EfficientNet-v2-S</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_v2_s">efficientnet_v2_s</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>21,136,440</p></td>
<td><p>789.91M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-v2-M</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_v2_m">efficientnet_v2_m</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>55,302,108</p></td>
<td><p>1.42B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>EfficientNet-v2-L</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_v2_l">efficientnet_v2_l</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>120,617,032</p></td>
<td><p>3.17B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>EfficientNet-v2-XL</p></td>
<td><p><a class="reference external" href="efficient/efficientnet_v2_xl">efficientnet_v2_xl</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>210,221,568</p></td>
<td><p>4.12B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="resnest">
<h2>ResNeSt<a class="headerlink" href="#resnest" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>ResNeSt introduces Split Attention Blocks, which divide feature maps into groups,
compute attention for each group, and reassemble them to enhance representational power.
It extends ResNet by integrating these blocks, achieving improved performance in image
recognition tasks with minimal computational overhead.</p>
<blockquote>
<div><p>Zhang, Hang, et al. ResNeSt: Split-Attention Networks. arXiv preprint
arXiv:2004.08955, 2020.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ResNeSt-14</p></td>
<td><p><a class="reference external" href="resnest/resnest_14">resnest_14</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>10,611,560</p></td>
<td><p>2.82B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNeSt-26</p></td>
<td><p><a class="reference external" href="resnest/resnest_26">resnest_26</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>17,069,320</p></td>
<td><p>3.72B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNeSt-50</p></td>
<td><p><a class="reference external" href="resnest/resnest_50">resnest_50</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>27,483,112</p></td>
<td><p>5.52B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNeSt-101</p></td>
<td><p><a class="reference external" href="resnest/resnest_101">resnest_101</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>48,274,760</p></td>
<td><p>10.43B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNeSt-200</p></td>
<td><p><a class="reference external" href="resnest/resnest_200">resnest_200</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>70,201,288</p></td>
<td><p>17.85B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNeSt-269</p></td>
<td><p><a class="reference external" href="resnest/resnest_269">resnest_269</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>110,929,224</p></td>
<td><p>22.98B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ResNeSt-50-4s2x40d</p></td>
<td><p><a class="reference external" href="resnest/resnest_50_4s2x40d">resnest_50_4s2x40d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>30,417,464</p></td>
<td><p>5.41B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ResNeSt-50_1s4x24d</p></td>
<td><p><a class="reference external" href="resnest/resnest_50_1s4x24d">resnest_50_1s4x24d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>25,676,872</p></td>
<td><p>5.14B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="convnext">
<h2>ConvNeXt<a class="headerlink" href="#convnext" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>ConvNeXt reimagines CNNs using principles inspired by vision transformers,
streamlining architectural design while preserving the efficiency of traditional CNNs.
It introduces design elements like simplified stem stages, inverted bottlenecks,
and expanded kernel sizes to enhance feature extraction.</p>
<blockquote>
<div><p><em>ConvNeXt</em></p>
<p>Liu, Zhuang, et al. A ConvNet for the 2020s. <em>arXiv preprint arXiv:2201.03545</em>, 2022.</p>
<p><em>ConvNeXt-v2</em></p>
<p>Liu, Ze, et al. ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders.
<em>arXiv preprint arXiv:2301.00808</em>, 2023.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ConvNeXt-Tiny</p></td>
<td><p><a class="reference external" href="convnext/convnext_tiny">convnext_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>28,589,128</p></td>
<td><p>4.73B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ConvNeXt-Small</p></td>
<td><p><a class="reference external" href="convnext/convnext_small">convnext_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>46,884,148</p></td>
<td><p>8.46B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ConvNeXt-Base</p></td>
<td><p><a class="reference external" href="convnext/convnext_base">convnext_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>88,591,464</p></td>
<td><p>15.93B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ConvNeXt-Large</p></td>
<td><p><a class="reference external" href="convnext/convnext_large">convnext_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>197,767,336</p></td>
<td><p>35.23B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ConvNeXt-XLarge</p></td>
<td><p><a class="reference external" href="convnext/convnext_xlarge">convnext_xlarge</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>350,196,968</p></td>
<td><p>62.08B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ConvNeXt-v2-Atto</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_atto">convnext_v2_atto</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>3,708,400</p></td>
<td><p>641.87M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ConvNeXt-v2-Femto</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_femto">convnext_v2_femto</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>5,233,240</p></td>
<td><p>893.05M</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ConvNeXt-v2-Pico</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_pico">convnext_v2_pico</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>9,066,280</p></td>
<td><p>1.52B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ConvNeXt-v2-Nano</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_nano">convnext_v2_nano</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>15,623,800</p></td>
<td><p>2.65B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ConvNeXt-v2-Tiny</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_tiny">convnext_v2_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>28,635,496</p></td>
<td><p>4.79B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ConvNeXt-v2-Base</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_base">convnext_v2_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>88,717,800</p></td>
<td><p>16.08B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ConvNeXt-v2-Large</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_large">convnext_v2_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>197,956,840</p></td>
<td><p>35.64B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ConvNeXt-v2-Huge</p></td>
<td><p><a class="reference external" href="convnext/convnext_v2_huge">convnext_v2_huge</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>660,289,640</p></td>
<td><p>120.89B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="inceptionnext">
<h2>InceptionNeXt<a class="headerlink" href="#inceptionnext" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>InceptionNeXt extends the Inception architecture by incorporating modern design
principles inspired by vision transformers. It refines multi-scale feature extraction
through dynamic kernel selection, depthwise convolutions, and enhanced normalization
techniques, preserving computational efficiency while improving performance across
diverse vision tasks.</p>
<blockquote>
<div><p>Yu, Weihao, et al. InceptionNeXt: When Inception Meets ConvNeXt.
<em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>,
2024, pp. 5672-5683.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>InceptionNeXt-Atto</p></td>
<td><p><a class="reference external" href="inception_next/inception_next_atto">inception_next_atto</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>4,156,520</p></td>
<td><p>582.25M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>InceptionNeXt-Tiny</p></td>
<td><p><a class="reference external" href="inception_next/inception_next_tiny">inception_next_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>28,083,832</p></td>
<td><p>4.48B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>InceptionNeXt-Small</p></td>
<td><p><a class="reference external" href="inception_next/inception_next_small">inception_next_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>49,431,544</p></td>
<td><p>8.82B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>InceptionNeXt-Base</p></td>
<td><p><a class="reference external" href="inception_next/inception_next_base">inception_next_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>86,748,840</p></td>
<td><p>15.47B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="coatnet">
<h2>CoAtNet<a class="headerlink" href="#coatnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>CoAtNet extends the hybrid architecture paradigm by integrating convolutional
and transformer-based designs. It enhances representation learning through
hierarchical feature extraction, leveraging early-stage depthwise convolutions
for locality and later-stage self-attention for global context. With relative
position encoding, pre-normalization, and an optimized scaling strategy,
CoAtNet achieves superior efficiency and performance across various vision tasks.</p>
<blockquote>
<div><p>Dai, Zihang, et al. CoAtNet: Marrying Convolution and Attention for All Data Sizes.
<em>Advances in Neural Information Processing Systems</em>, 2021, pp. 3965-3977.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>CoAtNet-0</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_0">coatnet_0</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>27,174,944</p></td>
<td><p>5.52B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CoAtNet-1</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_1">coatnet_1</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>53,330,240</p></td>
<td><p>12.32B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CoAtNet-2</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_2">coatnet_2</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>82,516,096</p></td>
<td><p>19.72B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CoAtNet-3</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_3">coatnet_3</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>157,790,656</p></td>
<td><p>37.17B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CoAtNet-4</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_4">coatnet_4</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>277,301,632</p></td>
<td><p>66.79B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CoAtNet-5</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_5">coatnet_5</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>770,124,608</p></td>
<td><p>189.34B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CoAtNet-6</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_6">coatnet_6</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>2,011,558,336</p></td>
<td><p>293.51B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CoAtNet-7</p></td>
<td><p><a class="reference external" href="coatnet/coatnet_7">coatnet_7</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>3,107,978,688</p></td>
<td><p>364.71B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="cspnet">
<h2>CSPNet<a class="headerlink" href="#cspnet" title="Link to this heading"></a></h2>
<p><span class="badge convnet">ConvNet</span> <span class="badge normal">Image Classification</span></p>
<p>CSPNet (Cross Stage Partial Network) introduces a split-transform-merge strategy
to optimize gradient flow and reduce computational redundancy in deep convolutional
architectures. By partitioning feature maps into two partsone passing through
a transformation block and the other bypassing itCSPNet improves parameter efficiency
and learning dynamics without sacrificing representational power.</p>
<blockquote>
<div><p>Wang, Chien-Yao, et al. CSPNet: A new backbone that can enhance learning capability
of CNN. <em>Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition workshops</em>. 2020.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>CSP-ResNet-50</p></td>
<td><p><a class="reference external" href="cspnet/csp_resnet_50">csp_resnet_50</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>22,463,016</p></td>
<td><p>376.71M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CSP-ResNeXt-50-32x4d</p></td>
<td><p><a class="reference external" href="cspnet/csp_resnext_50_32x4d">csp_resnext_50_32x4d</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>22,509,864</p></td>
<td><p>431.93M</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CSP-DarkNet-53</p></td>
<td><p><a class="reference external" href="cspnet/csp_darknet_53">csp_darknet_53</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>27,278,536</p></td>
<td><p>39.14M</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="visual-transformer-vit">
<h2>Visual Transformer (ViT)<a class="headerlink" href="#visual-transformer-vit" title="Link to this heading"></a></h2>
<p><span class="badge transformer">Transformer</span> <span class="badge vision_transformer">Vision Transformer</span> <span class="badge normal">Image Classification</span></p>
<p>The Vision Transformer (ViT) is a deep learning architecture introduced by
Dosovitskiy et al. in 2020, designed for image recognition tasks using self-attention
mechanisms. Unlike traditional convolutional neural networks (CNNs), ViT splits an
image into fixed-size patches, processes them as a sequence, and applies Transformer
layers to capture global dependencies.</p>
<blockquote>
<div><p>Dosovitskiy, Alexey, et al. An Image is Worth 16x16 Words: Transformers for
Image Recognition at Scale. <em>International Conference on Learning Representations</em>
(ICLR), 2020.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ViT-Ti</p></td>
<td><p><a class="reference external" href="vit/vit_tiny">vit_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>5,717,416</p></td>
<td><p>1.36B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ViT-S</p></td>
<td><p><a class="reference external" href="vit/vit_small">vit_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>22,050,664</p></td>
<td><p>4.81B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ViT-B</p></td>
<td><p><a class="reference external" href="vit/vit_base">vit_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>86,567,656</p></td>
<td><p>17.99B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>ViT-L</p></td>
<td><p><a class="reference external" href="vit/vit_large">vit_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>304,326,632</p></td>
<td><p>62.69B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>ViT-H</p></td>
<td><p><a class="reference external" href="vit/vit_huge">vit_huge</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>632,199,400</p></td>
<td><p>169.45B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="swin-transformer">
<h2>Swin Transformer<a class="headerlink" href="#swin-transformer" title="Link to this heading"></a></h2>
<p><span class="badge transformer">Transformer</span> <span class="badge vision_transformer">Vision Transformer</span> <span class="badge normal">Image Classification</span></p>
<p>The Swin Transformer is a hierarchical vision transformer introduced by
Liu et al. in 2021, designed for image recognition and dense prediction
tasks using self-attention mechanisms within shifted local windows.
Unlike traditional convolutional neural networks (CNNs) and the original
Vision Transformer (ViT)which splits an image into fixed-size patches
and processes them as a flat sequencethe Swin Transformer divides the
image into non-overlapping local windows and computes self-attention
within each window.</p>
<blockquote>
<div><p><em>Swin Transformer</em></p>
<p>Liu, Ze, et al. Swin Transformer: Hierarchical Vision Transformer using
Shifted Windows. arXiv preprint arXiv:2103.14030 (2021).</p>
<p><em>Swin Transformer-v2</em></p>
<p>Liu, Ze, et al. Swin Transformer V2: Scaling Up Capacity and Resolution.
arXiv preprint arXiv:2111.09883 (2021).</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Swin-T</p></td>
<td><p><a class="reference external" href="swin/swin_tiny">swin_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>28,288,354</p></td>
<td><p>4.95B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Swin-S</p></td>
<td><p><a class="reference external" href="swin/swin_small">swin_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>49,606,258</p></td>
<td><p>9.37B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Swin-B</p></td>
<td><p><a class="reference external" href="swin/swin_base">swin_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>87,768,224</p></td>
<td><p>16.35B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Swin-L</p></td>
<td><p><a class="reference external" href="swin/swin_large">swin_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>196,532,476</p></td>
<td><p>36.08B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Swin-v2-T</p></td>
<td><p><a class="reference external" href="swin/swin_v2_tiny">swin_v2_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>28,349,842</p></td>
<td><p>5.01B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Swin-v2-S</p></td>
<td><p><a class="reference external" href="swin/swin_v2_small">swin_v2_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>49,731,106</p></td>
<td><p>9.48B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Swin-v2-B</p></td>
<td><p><a class="reference external" href="swin/swin_v2_base">swin_v2_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>87,922,400</p></td>
<td><p>16.49B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Swin-v2-L</p></td>
<td><p><a class="reference external" href="swin/swin_v2_large">swin_v2_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>196,745,308</p></td>
<td><p>36.29B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Swin-v2-H</p></td>
<td><p><a class="reference external" href="swin/swin_v2_huge">swin_v2_huge</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>657,796,668</p></td>
<td><p>119.42B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Swin-v2-G</p></td>
<td><p><a class="reference external" href="swin/swin_v2_giant">swin_v2_giant</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>3,000,869,564</p></td>
<td><p>531.67B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="convolutional-transformer-cvt">
<h2>Convolutional Transformer (CvT)<a class="headerlink" href="#convolutional-transformer-cvt" title="Link to this heading"></a></h2>
<p><span class="badge transformer">Transformer</span> <span class="badge vision_transformer">Vision Transformer</span> <span class="badge normal">Image Classification</span></p>
<p>CvT (Convolutional Vision Transformer) combines self-attention with depthwise
convolutions to improve local feature extraction and computational efficiency.
This hybrid design retains the global modeling capabilities of Vision Transformers
while enhancing inductive biases, making it effective for image classification and
dense prediction tasks.</p>
<blockquote>
<div><p>Wu, Haiping, et al. CvT: Introducing Convolutions to Vision Transformers.
<em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em>,
2021, pp. 22-31.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>CvT-13</p></td>
<td><p><a class="reference external" href="cvt/cvt_13">cvt_13</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>19,997,480</p></td>
<td><p>4.83B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CvT-21</p></td>
<td><p><a class="reference external" href="cvt/cvt_21">cvt_21</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>31,622,696</p></td>
<td><p>7.57B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CvT-W24</p></td>
<td><p><a class="reference external" href="cvt/cvt_w24">cvt_w24</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,384,384)\)</span></p></td>
<td><p>277,196,392</p></td>
<td><p>62.29B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="pyramid-vision-transformer-pvt">
<h2>Pyramid Vision Transformer (PVT)<a class="headerlink" href="#pyramid-vision-transformer-pvt" title="Link to this heading"></a></h2>
<p><span class="badge transformer">Transformer</span> <span class="badge vision_transformer">Vision Transformer</span> <span class="badge normal">Image Classification</span></p>
<p>The <strong>Pyramid Vision Transformer (PVT)</strong> combines CNN-like pyramidal structures
with Transformer attention, capturing multi-scale features efficiently. It reduces
spatial resolution progressively and uses <strong>spatial-reduction attention (SRA)</strong>
to enhance performance in dense prediction tasks like detection and segmentation.</p>
<blockquote>
<div><p><em>PVT</em></p>
<p>Wang, Wenhai, et al. Pyramid Vision Transformer: A Versatile Backbone for Dense
Prediction without Convolutions. arXiv, 2021, arXiv:2102.12122.</p>
<p><em>PVT-v2</em></p>
<p>Wang, Wenhai, et al. PVTv2: Improved baselines with pyramid vision transformer.
<em>Computational Visual Media</em> 8.3 (2022): 415-424.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>PVT-Tiny</p></td>
<td><p><a class="reference external" href="pvt/pvt_tiny">pvt_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>12,457,192</p></td>
<td><p>2.02B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>PVT-Small</p></td>
<td><p><a class="reference external" href="pvt/pvt_small">pvt_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>23,003,048</p></td>
<td><p>3.93B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>PVT-Medium</p></td>
<td><p><a class="reference external" href="pvt/pvt_medium">pvt_medium</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>41,492,648</p></td>
<td><p>6.66B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>PVT-Large</p></td>
<td><p><a class="reference external" href="pvt/pvt_large">pvt_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>55,359,848</p></td>
<td><p>8.71B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>PVT-Huge</p></td>
<td><p><a class="reference external" href="pvt/pvt_huge">pvt_huge</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>286,706,920</p></td>
<td><p>48.63B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>PVT-v2-B0</p></td>
<td><p><a class="reference external" href="pvt/pvt_v2_b0">pvt_v2_b0</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>3,666,760</p></td>
<td><p>677.67M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>PVT-v2-B1</p></td>
<td><p><a class="reference external" href="pvt/pvt_v2_b1">pvt_v2_b1</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>14,009,000</p></td>
<td><p>2.32B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>PVT-v2-B2</p></td>
<td><p><a class="reference external" href="pvt/pvt_v2_b2">pvt_v2_b2</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>25,362,856</p></td>
<td><p>4.39B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>PVT-v2-B2-Linear</p></td>
<td><p><a class="reference external" href="pvt/pvt_v2_b2_li">pvt_v2_b2_li</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>22,553,512</p></td>
<td><p>4.27B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>PVT-v2-B3</p></td>
<td><p><a class="reference external" href="pvt/pvt_v2_b3">pvt_v2_b3</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>45,238,696</p></td>
<td><p>7.39B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>PVT-v2-B4</p></td>
<td><p><a class="reference external" href="pvt/pvt_v2_b4">pvt_v2_b4</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>62,556,072</p></td>
<td><p>10.80B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>PVT-v2-B5</p></td>
<td><p><a class="reference external" href="pvt/pvt_v2_b5">pvt_v2_b5</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>82,882,984</p></td>
<td><p>13.47B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="crossvit">
<h2>CrossViT<a class="headerlink" href="#crossvit" title="Link to this heading"></a></h2>
<p><span class="badge transformer">Transformer</span> <span class="badge vision_transformer">Vision Transformer</span> <span class="badge normal">Image Classification</span></p>
<p>CrossViT is a vision transformer architecture that combines multi-scale
tokenization by processing input images at different resolutions in parallel,
enabling it to capture both fine-grained and coarse-grained visual features.
It uses a novel cross-attention mechanism to fuse information across these scales,
improving performance on image recognition tasks.</p>
<blockquote>
<div><p>Chen, Chun-Fu, Quanfu Fan, and Rameswar Panda. CrossViT: Cross-Attention Multi-Scale
Vision Transformer for Image Classification. arXiv, 2021. arXiv:2103.14899.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>CrossViT-Ti</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_tiny">crossvit_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>7,014,800</p></td>
<td><p>1.73B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CrossViT-S</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_small">crossvit_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>26,856,272</p></td>
<td><p>5.94B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CrossViT-B</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_base">crossvit_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>105,025,232</p></td>
<td><p>21.85B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CrossViT-9</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_9">crossvit_9</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>8,553,296</p></td>
<td><p>2.01B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CrossViT-15</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_15">crossvit_15</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>27,528,464</p></td>
<td><p>6.13B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CrossViT-18</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_18">crossvit_18</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>43,271,408</p></td>
<td><p>9.48B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CrossViT-9</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_9_dagger">crossvit_9_dagger</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>8,776,592</p></td>
<td><p>2.15B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>CrossViT-15</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_15_dagger">crossvit_15_dagger</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>28,209,008</p></td>
<td><p>6.45B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>CrossViT-18</p></td>
<td><p><a class="reference external" href="crossvit/crossvit_18_dagger">crossvit_18_dagger</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>44,266,976</p></td>
<td><p>9.93B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="maxvit">
<h2>MaxViT<a class="headerlink" href="#maxvit" title="Link to this heading"></a></h2>
<p><span class="badge transformer">Transformer</span> <span class="badge vision_transformer">Vision Transformer</span> <span class="badge normal">Image Classification</span></p>
<p>MaxViT is a hybrid vision architecture that combines convolution, windowed attention,
and grid-based attention in a multi-axis design. This hierarchical structure enables
MaxViT to efficiently capture both local and global dependencies, making it effective
for various vision tasks with high accuracy and scalability.</p>
<blockquote>
<div><p>Tu, Zihang, et al. <em>MaxViT: Multi-Axis Vision Transformer</em>. arXiv, 2022, arXiv:2204.01697.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MaxViT-T</p></td>
<td><p><a class="reference external" href="maxvit/maxvit_tiny">maxvit_tiny</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>25,081,416</p></td>
<td><p>5.60B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>MaxViT-S</p></td>
<td><p><a class="reference external" href="maxvit/maxvit_small">maxvit_small</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>55,757,304</p></td>
<td><p>10.59B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>MaxViT-B</p></td>
<td><p><a class="reference external" href="maxvit/maxvit_base">maxvit_base</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>96,626,776</p></td>
<td><p>21.83B</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>MaxViT-L</p></td>
<td><p><a class="reference external" href="maxvit/maxvit_large">maxvit_large</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>171,187,880</p></td>
<td><p>38.51B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>MaxViT-XL</p></td>
<td><p><a class="reference external" href="maxvit/maxvit_xlarge">maxvit_xlarge</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>383,734,024</p></td>
<td><p>83.74B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="efficientformer">
<h2>EfficientFormer<a class="headerlink" href="#efficientformer" title="Link to this heading"></a></h2>
<p><span class="badge transformer">Transformer</span> <span class="badge vision_transformer">Vision Transformer</span> <span class="badge normal">Image Classification</span></p>
<p>EfficientFormer is a lightweight and efficient vision transformer architecture designed
for mobile and edge devices. By combining the strengths of convolutional inductive biases
with self-attention in a hybrid structure, EfficientFormer achieves a strong balance
between accuracy and computational efficiency.</p>
<blockquote>
<div><p>Li, Yanyu, et al. EfficientFormer: Vision Transformers at MobileNet Speed.
arXiv, 2022, arXiv:2206.01191.</p>
</div></blockquote>
<div class="table-wrapper docutils container">
<table class="docutils align-left">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Model</p></th>
<th class="head"><p>Input Shape</p></th>
<th class="head"><p>Parameter Count</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Pre-Trained</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>EfficientFormer-L1</p></td>
<td><p><a class="reference external" href="efficientformer/efficientformer_l1">efficientformer_l1</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>11,840,928</p></td>
<td><p>316.47M</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>EfficientFormer-L3</p></td>
<td><p><a class="reference external" href="efficientformer/efficientformer_l3">efficientformer_l3</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>30,893,000</p></td>
<td><p>1.07B</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>EfficientFormer-L7</p></td>
<td><p><a class="reference external" href="efficientformer/efficientformer_l7">efficientformer_l7</a></p></td>
<td><p><span class="math notranslate nohighlight">\((N,3,224,224)\)</span></p></td>
<td><p>81,460,328</p></td>
<td><p>3.44B</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<p><em>To be implemented</em></p>
</section>
</section>

        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"><div class="navigation-prev">
    <a href="../mixins/PreTrainedModelMixin.html">
      <i class="i-lucide chevron-left"></i>
      <div class="page-info">
        <span>Previous</span><div class="title">PreTrainedModelMixin</div></div>
    </a>
  </div><div class="navigation-next">
    <a href="lenet/LeNet.html">
      <div class="page-info">
        <span>Next</span>
        <div class="title">LeNet</div>
      </div>
      <i class="i-lucide chevron-right"></i>
    </a>
  </div></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, ChanLumerico</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../../_static/documentation_options.js?v=519550c4"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../../_static/shibuya.js?v=cac61aee"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/mermaid-zoom.js?v=0408cfdf"></script></body>
</html>