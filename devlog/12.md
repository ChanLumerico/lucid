## ğŸ“¦ Datasetê³¼ DataLoader ì„¤ê³„

Lucidì—ì„œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ ì‚¬ìš©ìê°€ ê°€ì¥ ìì£¼ ë§Œë‚˜ëŠ” ì˜ì—­ì´ë‹¤. PyTorchì˜ Dataset/DataLoaderë¥¼ ê±°ì˜ ìŠµê´€ì²˜ëŸ¼ ì“°ë˜ ì…ì¥ì—ì„œ, Lucidë„ **ìµìˆ™í•œ ì‚¬ìš©ê°**ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í–ˆë‹¤. ë™ì‹œì— MLXì™€ NumPyë¥¼ í˜¼ìš©í•˜ëŠ” í™˜ê²½ì—ì„œ **ê°€ë³ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë™ì‘**ì„ ìœ ì§€í•´ì•¼ í–ˆë‹¤. ì´ ë¬¸ì„œëŠ” `lucid/data/_base.py`, `_util.py`ë¥¼ êµ¬í˜„í•˜ë©° ì–´ë–¤ ì„ íƒì„ í–ˆê³ , ì–´ë””ì„œ ì‹œê°„ì„ ìŸì•˜ëŠ”ì§€ë¥¼ ê¸°ìˆ í•œë‹¤.

---

### ğŸ§­ ì„¤ê³„ ì›ì¹™

- **í˜¸í™˜ì„±**: `__getitem__`, `__len__`, DataLoader ì¸í„°í˜ì´ìŠ¤ë¥¼ PyTorchì™€ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ ìœ ì§€.
- **ë‹¨ìˆœí™”**: ë©€í‹°í”„ë¡œì„¸ì‹±/worker, pin_memory ë“±ì€ ì œì™¸. ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ì— ì§‘ì¤‘.
- **ë””ë°”ì´ìŠ¤ íë¦„**: `TensorDataset.to(device)`ë¡œ ëª¨ë¸ `.to()`ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ë™.
- **ëª…í™•í•œ ì—ëŸ¬**: ê¸¸ì´ ë¶ˆì¼ì¹˜, ì˜ëª»ëœ ì¸ë±ìŠ¤, ë””ë°”ì´ìŠ¤ ê¹¨ì§ ë“±ì— ëŒ€í•´ ì¦‰ì‹œ ëª…í™•í•œ ì˜ˆì™¸ë¥¼ ë˜ì§„ë‹¤.

ì²˜ìŒì—ëŠ” PyTorch ì˜µì…˜ì„ ëª¨ë‘ ë”°ë¼ê°ˆ ìƒê°ì´ì—ˆì§€ë§Œ, MLXì˜ lazy íŠ¹ì„±ê³¼ Mac í™˜ê²½ì„ ê³ ë ¤í•´ "í•„ìš”í•œ ìµœì†Œ"ë¥¼ ì„ íƒí–ˆë‹¤. ë‚˜ë¨¸ì§€ëŠ” API ëª¨ì–‘ì„ ë§ì¶° ë‘ê³  í›„ì† ë‹¨ê³„ì—ì„œ í™•ì¥í•  ìˆ˜ ìˆë„ë¡ ì—´ì–´ë‘ì—ˆë‹¤.

### ğŸ§± `Dataset` ë² ì´ìŠ¤ â€“ ê¸°ë³¸ í‹€ ë§ˆë ¨

**ê²½ë¡œ**: [`lucid/data/_base.py`](https://github.com/ChanLumerico/lucid/blob/main/lucid/data/_base.py#L9-L36)

```python
class Dataset(ABC):
    @abstractmethod
    def __getitem__(self, idx): ...

    @abstractmethod
    def __len__(self): ...

    def __add__(self, other): 
        return ConcatDataset([self, other])

    def __iter__(self):
        for i in range(len(self)): yield self[i]
```

PyTorchì²˜ëŸ¼ ë² ì´ìŠ¤ëŠ” ì•„ë¬´ ê²ƒë„ ì•ˆ í•œë‹¤. transform í›…ì´ë‚˜ ìºì‹±ì„ ë„£ì„ê¹Œ ê³ ë¯¼í–ˆì§€ë§Œ, ê°•ì œ ê¸°ëŠ¥ì´ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ì‚¬ìš©ì ììœ ë„ê°€ ì¤„ì—ˆë‹¤. `__add__`ë¡œ ë°ì´í„°ì…‹ ê²°í•©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì§€ì›í•˜ê³ , `__iter__`ë¥¼ ì œê³µí•´ ë‹¨ìˆœ ìˆœíšŒë„ ê°€ëŠ¥í•˜ê²Œ í–ˆë‹¤.

#### ì˜ˆì‹œ
```python
class MyDataset(Dataset):
    def __init__(self, X, y): 
        self.X, self.y = X, y

    def __getitem__(self, idx): 
        return self.X[idx], self.y[idx]

    def __len__(self): 
        return len(self.X)
```

ë² ì´ìŠ¤ë¥¼ ê°€ë³ê²Œ ìœ ì§€í•œ ë•ë¶„ì— ì‚¬ìš©ìëŠ” transform, caching, on-the-fly augmentation ë“±ì„ ìƒì†ìœ¼ë¡œ ììœ ë¡­ê²Œ ë§ë¶™ì¼ ìˆ˜ ìˆë‹¤. ì´ˆê¸°ì—ëŠ” ë¡œê¹… í›…ì„ ì‹œë„í–ˆì§€ë§Œ, ì‚¬ìš©ì ì •ì˜ `__getitem__`ê³¼ ì¶©ëŒí•´ ì œê±°í–ˆë‹¤.

### ğŸ§© `Subset` â€“ ì†ì„± ìœ„ì„ê³¼ ì¸ë±ìŠ¤ ë˜í•‘

**ê²½ë¡œ**: [`lucid/data/_base.py`](https://github.com/ChanLumerico/lucid/blob/main/lucid/data/_base.py#L38-L66)

- ì•„ì´ë””ì–´: `dataset[indices[idx]]`ë¥¼ ë˜í•‘.
- `__iter__`ë¥¼ indices ê¸°ë°˜ìœ¼ë¡œ ì¬ì •ì˜.
- `__getattr__`ë¡œ ì›ë³¸ ì†ì„± ìœ„ì„(PyTorch íŒ¨í„´).

ì´ˆê¸°ì—ëŠ” ì†ì„± ìœ„ì„ ì¤‘ ì¼ë¶€ê°€ ë®ì—¬ ì¬ê·€ í˜¸ì¶œì´ ë°œìƒí•˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤. ìœ„ì„ ë¡œì§ì„ ë‹¨ìˆœíˆ `getattr(self.dataset, name)`ìœ¼ë¡œ ì œí•œí•´ í•´ê²°í–ˆë‹¤. ìŒìˆ˜ ì¸ë±ìŠ¤ëŠ” ì›ë³¸ ê¸¸ì´ë¥¼ ë”í•´ ì²˜ë¦¬í•´ PyTorch ë™ì‘ê³¼ ë§ì·„ë‹¤.

#### ì˜ˆì‹œ
```python
train_ds = Subset(full_ds, list(range(0, 800)))
val_ds   = Subset(full_ds, list(range(800, 1000)))
```

### ğŸ§Š `TensorDataset` â€“ ê¸¸ì´ ê²€ì¦ê³¼ ë””ë°”ì´ìŠ¤ ë³´ì¡´

**ê²½ë¡œ**: [`lucid/data/_base.py`](https://github.com/ChanLumerico/lucid/blob/main/lucid/data/_base.py#L68-L113)

- ìµœì†Œ 1ê°œ í…ì„œ, ëª¨ë‘ ê°™ì€ ê¸¸ì´, 1D ì´ìƒ ê°•ì œ.
- ì…ë ¥ì´ Tensor/array í˜¼í•©ì´ì–´ë„ `_check_is_tensor`ë¡œ ìŠ¹ê²©í•´ ë””ë°”ì´ìŠ¤/ë°±ì—”ë“œ ì •ë³´ë¥¼ ìœ ì§€.
- `to(device)`ë¡œ ë‚´ë¶€ í…ì„œ ì¼ê´„ ì´ë™.

ê¸¸ì´ ê²€ì¦ì„ ì†Œí™€íˆ í–ˆë‹¤ê°€ ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ í…ì„œë¥¼ ë¬¶ì—ˆì„ ë•Œ ì¸ë±ì‹±ì´ ë’¤í‹€ë¦¬ëŠ” ë¬¸ì œë¥¼ ê²ªì—ˆë‹¤. PyTorchì²˜ëŸ¼ "ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì˜ˆì™¸"ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë„£ì—ˆë‹¤. MLX í…ì„œì™€ NumPy í…ì„œê°€ ì„ì¼ ë•Œ ì¥ì¹˜ ì •ë³´ê°€ ì‚¬ë¼ì§€ëŠ” ë¬¸ì œëŠ” ëª¨ë“  ì…ë ¥ì„ Tensorë¡œ ìŠ¹ê²©í•˜ê³ , `.to(device)`ì—ì„œ ìƒˆ íŠœí”Œë¡œ ì¬í• ë‹¹í•˜ì—¬ í•´ê²°í–ˆë‹¤.

#### ì˜ˆì‹œ
```python
X = lucid.randn(100, 32); y = lucid.randint(0, 10, (100,))
ds = TensorDataset(X, y).to("gpu")
```

### ğŸ§± `ConcatDataset` â€“ ìŒìˆ˜ ì¸ë±ìŠ¤ì™€ ëˆ„ì  í¬ê¸°

**ê²½ë¡œ**: [`lucid/data/_base.py`](https://github.com/ChanLumerico/lucid/blob/main/lucid/data/_base.py#L115-L158)

ì—¬ëŸ¬ Datasetì„ ì´ì–´ë¶™ì´ê³  `cumulative_sizes`ë¡œ ìœ„ì¹˜ë¥¼ ë¹ ë¥´ê²Œ ì°¾ëŠ”ë‹¤. ìŒìˆ˜ ì¸ë±ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ë‹¤ê°€ off-by-one ë²„ê·¸ê°€ ìˆì—ˆëŠ”ë°, PyTorchì™€ ë™ì¼í•˜ê²Œ ê¸¸ì´ì— ë”í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í†µì¼í–ˆë‹¤. ëˆ„ì  í¬ê¸°ë¥¼ ë§¤ ì ‘ê·¼ë§ˆë‹¤ ê³„ì‚°í•´ $\mathcal{O}(n)$ ë¹„ìš©ì´ ë°œìƒí•˜ë˜ ì´ˆê¸° ë²„ì „ì€, ìƒì„±ìì—ì„œ í•œ ë²ˆë§Œ ê³„ì‚°í•˜ë„ë¡ ë³€ê²½í•´ í•´ê²°í–ˆë‹¤.

#### ì˜ˆì‹œ
```python
full = ConcatDataset([train_ds, extra_ds])
last = full[-1]
```

### ğŸšš `DataLoader` â€“ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°ì˜ í•µì‹¬

**ê²½ë¡œ**: [`lucid/data/_base.py`](https://github.com/ChanLumerico/lucid/blob/main/lucid/data/_base.py#L160-L233)

- ì¸ë±ìŠ¤ ëª©ë¡ì„ ë§Œë“¤ì–´ ë°°ì¹˜ ë‹¨ìœ„ ìŠ¬ë¼ì´ìŠ¤, `shuffle=True`ë©´ epochë§ˆë‹¤ ì¬ì…”í”Œ.
- `default_collate`: íŠœí”Œ/ë¦¬ìŠ¤íŠ¸ batchëŠ” ì „ì¹˜ í›„ `lucid.stack`, TensorëŠ” ë°”ë¡œ `stack`, ê¸°íƒ€ëŠ” ì›ë³¸ ìœ ì§€.

ê°€ì¥ ë§ì€ ìˆ˜ì •ì´ collateì˜€ë‹¤. ì²˜ìŒ `np.stack`ì„ ì¼ë”ë‹ˆ MLX í…ì„œê°€ ì„ì´ë©´ ë””ë°”ì´ìŠ¤ê°€ ê¹¨ì¡Œë‹¤. Lucidì˜ `stack`ìœ¼ë¡œ í†µì¼í•´ ë””ë°”ì´ìŠ¤/ë°±ì—”ë“œ ì¼ê´€ì„±ì„ í™•ë³´í–ˆë‹¤. íŠœí”Œ ì „ì¹˜ ê³¼ì •ì—ì„œ ì¶• ìˆœì„œë¥¼ ì˜ëª» ì¡ì•„ shape mismatchê°€ ë‚¬ìœ¼ë‚˜, `zip(*)`ë¡œ ì „ì¹˜ í›„ ê° ìš”ì†Œë¥¼ stackí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì •ë¦¬í–ˆë‹¤. ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ëœ ì°¼ì„ ë•ŒëŠ” `min(start+batch_size, len(indices))`ë¡œ ì•ˆì „í•˜ê²Œ ìŠ¬ë¼ì´ìŠ¤í–ˆë‹¤.

#### ì‚¬ìš© ì˜ˆ
```python
loader = DataLoader(ds, batch_size=32, shuffle=True)
for x, y in loader:
    ...
```

#### ì»¤ìŠ¤í…€ collate
```python
def my_collate(batch):
    xs, ys = zip(*batch)
    return lucid.stack(xs, axis=0), lucid.stack(ys, axis=0)
loader = DataLoader(ds, batch_size=16, collate_fn=my_collate)
```

### ğŸ”€ `random_split` â€“ ì†Œìˆ˜ ê¸¸ì´ì™€ ì‹œë“œ ê´€ë¦¬

**ê²½ë¡œ**: [`lucid/data/_util.py`](https://github.com/ChanLumerico/lucid/blob/main/lucid/data/_util.py#L5-L53)

ë¹„ìœ¨ ë¶„í•  ì‹œ í•©ì´ $1$ì´ ì•„ë‹ˆë©´ ì˜ˆì™¸ë¥¼ ë˜ì§€ê³ , ë°˜ì˜¬ë¦¼ ì˜¤ì°¨ë¡œ ë‚¨ëŠ” ìƒ˜í”Œì€ ì•ì—ì„œë¶€í„° ë¶„ë°°í•œë‹¤. ë¶€ë™ì†Œìˆ˜ì  í•©ì´ $0.999999\ldots$ ë¡œ ë–¨ì–´ì§€ëŠ” ì‚¬ë¡€ê°€ ìˆì–´ `math.isclose`ë¥¼ ì ìš©í–ˆë‹¤. ì¸ë±ìŠ¤ ì…”í”Œì€ `random.Random(seed)`ë¡œ ì§€ì—­ RNGë¥¼ ë§Œë“¤ì–´ ì „ì—­ ìƒíƒœë¥¼ ì˜¤ì—¼ì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤.

#### ì˜ˆì‹œ
```python
train_ds, val_ds = random_split(ds, [0.8, 0.2], seed=42)
```

### ğŸ§­ PyTorchì™€ì˜ í˜¸í™˜ì„±/ì°¨ì´ â€“ ì˜ë„ì  ê°„ì†Œí™”

- **ë¹„ìŠ·í•œ ì **: ì¸í„°í˜ì´ìŠ¤, `Subset`/`ConcatDataset`, `random_split`, `collate_fn`, `shuffle`.
- **ë‹¤ë¥¸ ì **: ë©€í‹°í”„ë¡œì„¸ì‹±/worker ë¯¸ì§€ì›, pin_memory ì—†ìŒ, `TensorDataset.to(device)` ê°™ì€ í¸ì˜ ì¶”ê°€, `default_collate`ê°€ Lucid Tensor ìŠ¤íƒì„ ì‚¬ìš©.

ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ëº€ ì´ìœ ëŠ” MLX lazy íŠ¹ì„±ê³¼ Macì˜ í¬í¬ ì œì•½ì„ ê°ì•ˆí–ˆì„ ë•Œ ë‹¨ìˆœí•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìª½ì´ ë‚«ë‹¤ê³  íŒë‹¨í–ˆê¸° ë•Œë¬¸ì´ë‹¤. `pin_memory`ë„ Apple ì‹¤ë¦¬ì½˜ í†µí•© ë©”ëª¨ë¦¬ í™˜ê²½ì—ì„œ ì´ì ì´ ì œí•œì ì´ë¼ ì œì™¸í–ˆë‹¤. ëŒ€ì‹  API ëª¨ì–‘ì„ PyTorchì™€ ë§ì¶°ë‘ì–´, ì¶”í›„ í•„ìš” ì‹œ ì˜µì…˜ì„ ì¶”ê°€í•´ë„ ì‚¬ìš©ì ê²½í—˜ì„ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ í–ˆë‹¤.

### ğŸ” ì¶”ê°€ êµ¬í˜„ ë””í…Œì¼ â€“ ì—ëŸ¬ ë©”ì‹œì§€ì™€ ë¡œê¹…

- ê¸¸ì´ ë¶ˆì¼ì¹˜, $\mathbb{R}^0$ í…ì„œ ì…ë ¥, ë¹ˆ ë°ì´í„°ì…‹ ë“±ì€ ì¦‰ì‹œ ëª…í™•í•œ ì˜ˆì™¸ ë©”ì‹œì§€ë¥¼ ë˜ì§€ë„ë¡ í–ˆë‹¤.
- DataLoaderì—ì„œ ì¸ë±ìŠ¤ ì´ˆê³¼ ì‹œ `StopIteration`ìœ¼ë¡œ ì¢…ë£Œ, ë‚´ë¶€ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•´ ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í–ˆë‹¤.
- `__repr__`ë¥¼ ê°„ë‹¨íˆ ì œê³µí•´ ë””ë²„ê¹… ì‹œ ë°ì´í„°ì…‹ í¬ê¸°, í…ì„œ shape, ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ ë°”ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤(`TensorDataset`, `Subset` ë“±).

ì´ëŸ° ì„¸ë¶€ ë¡œê¹…ì€ ê°œë°œ ì¤‘ í˜¼ì„ ì„ ì¤„ì˜€ê³ , ì‚¬ìš©ìê°€ ë°ì´í„° êµ¬ì„±ì„ ëˆˆìœ¼ë¡œ ê²€ì¦í•˜ê¸° ì‰½ê²Œ í•´ì£¼ì—ˆë‹¤.

---

### ğŸ§µ ì‹¤ì „ ì˜ˆì œ: ì´ë¯¸ì§€ ë¶„ë¥˜ ë¯¸ë‹ˆ ë£¨í”„

```python
import lucid
import lucid.nn as nn
from lucid.data import TensorDataset, DataLoader, random_split

X = lucid.randn(1000, 3, 32, 32)
y = lucid.randint(0, 10, (1000,))

dataset = TensorDataset(X, y)
train_ds, val_ds = random_split(dataset, [0.8, 0.2], seed=123)

train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=128, shuffle=False)

model = nn.Sequential(
    nn.Linear(3 * 32 * 32, 128), 
    nn.ReLU(), 
    nn.Linear(128, 10),
).to("gpu")

opt = lucid.optim.SGD(model.parameters(), defaults={"lr": 1e-2})

for epoch in range(5):
    model.train()
    for x, y in train_loader:
        x = x.to("gpu").reshape(x.shape[0], -1)
        y = y.to("gpu")
        opt.zero_grad()

        loss = nn.functional.cross_entropy(model(x), y)
        loss.eval()
        loss.backward()
        opt.step()

    model.eval()
    correct = total = 0
    for x, y in val_loader:
        x = x.to("gpu").reshape(x.shape[0], -1)
        y = y.to("gpu")

        preds = model(x).argmax(axis=1)
        correct += (preds == y).sum().item()
        total += y.size

    print(f"Epoch {epoch} acc={correct/total:.3f}")
```

PyTorch ì‚¬ìš©ê°ê³¼ ê±°ì˜ ë™ì¼í•œ íë¦„ì„ Lucidì—ì„œ ì¬í˜„í•œë‹¤. MLXì˜ lazy íŠ¹ì„±ë§Œ `loss.eval()`ë¡œ ì±™ê¸°ë©´ ëœë‹¤.

---

### âœ… ì •ë¦¬

`lucid.data`ëŠ” "ìµìˆ™í•œë° ê°€ë²¼ìš´" ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ëª©í‘œë¡œ, PyTorch í•µì‹¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìµœì†Œ êµ¬í˜„ìœ¼ë¡œ ì¬í˜„í–ˆë‹¤. ê¸¸ì´ ê²€ì¦, ìŒìˆ˜ ì¸ë±ìŠ¤, ë””ë°”ì´ìŠ¤ ê¹¨ì§ ê°™ì€ ë¬¸ì œë¥¼ ë°Ÿê³  ìˆ˜ì •í•˜ë©´ì„œ MLX/NumPy í˜¼ìš© í™˜ê²½ì—ì„œë„ ì¼ê´€ë˜ê²Œ ë™ì‘í•˜ëŠ” ë¼ˆëŒ€ë¥¼ ë§Œë“¤ì—ˆë‹¤. ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ì™€ ê¸°ë³¸ collateë§Œ ì§€ì›í•˜ì§€ë§Œ, API ëª¨ì–‘ê³¼ ê·œì•½ì„ PyTorchì™€ ë§ì¶° ë‘ì—ˆê¸°ì— ì´í›„ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ë”ë¼ë„ ì‚¬ìš©ì ê²½í—˜ì„ í•´ì¹˜ì§€ ì•ŠëŠ” ë²”ìœ„ì—ì„œ í™•ì¥í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.
